{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10774,"status":"ok","timestamp":1654011047022,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"tZ2u6g-ddRd2","outputId":"f778824a-bea3-411c-ed1b-70861b92fe2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13829,"status":"ok","timestamp":1655200044181,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"NEjh_m0EeaUp","outputId":"b533d671-59f0-4afe-fe08-18fa2f094e19"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n","\u001b[K     |████████████████████████████████| 346 kB 31.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.8 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting dill<0.3.5\n","  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 7.8 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 68.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 70.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 58.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 66.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 76.8 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.5 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 73.3 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 51.9 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 56.6 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, dill, aiohttp, xxhash, responses, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.5.1\n","    Uninstalling dill-0.3.5.1:\n","      Successfully uninstalled dill-0.3.5.1\n","  Attempting uninstall: multiprocess\n","    Found existing installation: multiprocess 0.70.13\n","    Uninstalling multiprocess-0.70.13:\n","      Successfully uninstalled multiprocess-0.70.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 dill-0.3.4 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.7.0 multidict-6.0.2 multiprocess-0.70.12.2 pyyaml-6.0 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10074,"status":"ok","timestamp":1655200054235,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"bB6uFtNBgOxM","outputId":"c291ce7b-3b2a-47b8-91a0-b7d6ab01ef43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 28.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 60.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.12.1 transformers-4.19.4\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9920,"status":"ok","timestamp":1655200064137,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"eQwUHLEceCk7","outputId":"d3789644-0164-4be3-c3de-d884c761b355"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["1.11.0+cu113\n"]}],"source":["from tqdm.auto import tqdm\n","import pandas as pd\n","from IPython.display import display\n","import torch\n","import numpy as np\n","import shutil\n","import os\n","import json\n","import gc\n","import datetime\n","import torch.nn as nn\n","from abc import ABC, abstractmethod\n","import torch.optim as optim\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","from scipy.special import softmax\n","from sklearn.metrics import f1_score\n","import sklearn\n","import psutil  # RAM usage\n","import re\n","import random\n","import pickle\n","import datasets\n","import copy\n","from copy import deepcopy\n","import sys\n","from ast import literal_eval\n","from transformers import AutoTokenizer, AutoModel\n","import nltk\n","nltk.download('punkt')\n","from nltk import word_tokenize\n","from sklearn.model_selection import train_test_split\n","import unicodedata\n","\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1655200064140,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"UZljGUQ1iN2m"},"outputs":[],"source":["from nltk.tokenize import RegexpTokenizer\n","\n","punctuation = r'[]!\"$%&\\'()*+,./:;=#@?[\\\\^_`{|}~-]?'\n","tok = RegexpTokenizer(r'\\w+' + r'\\w+?|[^\\s]+?')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1655200064143,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"Zh57fSdDeVMR","outputId":"6a370995-f182-435a-e62a-2da5b8ccce9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["\"\"\"# Configs\"\"\"\n","\n","class Dataset_info:\n","    def __init__(self, dataset_name, num_of_spans, max_span_length=5, ignore_classes=[], manual_text=None):\n","        self.dataset_name = dataset_name\n","        self.num_of_spans = num_of_spans\n","        self.ignore_classes = ignore_classes  # ignore other class in rel (semeval)\n","        self.manual_text = manual_text\n","\n","POOL_METHOD = \"attn\"  # 'max', 'attn'\n","BATCH_SIZE = 32\n","#SEED = 0\n","LEARNING_RATE = 5e-5\n","DEVICE = 'cuda' if torch.cuda.is_available() else \"cpu\"\n","\n","CACHE_LEN = 500\n","GPU_CACHE_LEN = 600  # 600\n","RAM_CACHE_LEN = 1500  # 2000\n","\n","print(DEVICE)\n","\n","def get_dataset_info(info1):\n","  info1 = info1.split('_')\n","  return '_'.join([info1[0], info1[0], info1[1]])\n","\n","dataset_info_dict = {\n","    \"lcc\": Dataset_info(\"lcc_lcc_lcc\", num_of_spans=1),\n","    \"yulia\": Dataset_info(\"yulia_yulia_yulia\", num_of_spans=1),\n","    \"wiktionary\": Dataset_info(\"wiktionary_wiktionary_wiktionary\", num_of_spans=1),\n","    \"lcc_yulia\": Dataset_info(\"lcc_lcc_yulia\", num_of_spans=1),\n","    \"lcc_wiktionary\": Dataset_info(\"lcc_lcc_wiktionary\", num_of_spans=1),\n","    \"yulia_lcc\": Dataset_info(\"yulia_yulia_lcc\", num_of_spans=1),\n","    \"yulia_wiktionary\": Dataset_info(\"yulia_yulia_wiktionary\", num_of_spans=1),\n","    \"wiktionary_lcc\": Dataset_info(\"wiktionary_wiktionary_lcc\", num_of_spans=1),\n","    \"wiktionary_yulia\": Dataset_info(\"wiktionary_wiktionary_yulia\", num_of_spans=1),\n","    \"lcc_rusidio\": Dataset_info(\"lcc_lcc_rusidio\", num_of_spans=1),\n","    \"yulia_rusidio\": Dataset_info(\"yulia_yulia_rusidio\", num_of_spans=1),\n","    \"wiktionary_rusidio\": Dataset_info(\"wiktionary_wiktionary_rusidio\", num_of_spans=1),\n","}\n","for dname in [\"lcc+yulia\", \"lcc+wiktionary\", \"lcc+yulia+wiktionary\", \"yulia+wiktionary\"]:\n","  dataset_info_dict[dname+'_'+'rusidio'] = Dataset_info(get_dataset_info(dname+'_'+'rusidio'), num_of_spans=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o3Pn0NWEb0af"},"outputs":[],"source":["acc = s[5:6]\n","df = pd.read_csv('./drive/MyDrive/rscf/wiktionary/wiktionary_verb_examples.csv', index_col=0)\n","df = df.dropna()\n","dfs = [x for _, x in df.groupby(df['verblemma'])]\n","boths = []\n","for d in dfs:\n","  if d.Class.value_counts().shape[0] > 1:\n","    boths.append(d)\n","len(boths), sum([both.shape[0] for both in boths])\n","df = pd.concat(boths)\n","def get_spans(sent, wordform):\n","        try:\n","          s = sent.index(wordform)\n","          return [s, s+1]\n","        except:\n","          print(wordform, sent)\n","def get_folds(x):\n","        for fold, vbs in verbs.items():\n","          if x in vbs:\n","            return fold\n","def text_proc(x):\n","  x = x.replace(acc, '')\n","  return tok.tokenize(x)\n","df['wordforms'] = df.wordforms.apply(lambda x: x.replace(acc, ''))\n","df['text'] = df.sent.apply(text_proc)\n","df['span1'] = df.apply(lambda x: get_spans(x.text, x.wordforms), axis=1)\n","df = df.sample(frac=1)\n","train, test1 = train_test_split(df, test_size=0.3)\n","test, dev = train_test_split(test1, test_size=0.33)\n","train['fold'] = 'train'\n","dev['fold'] = 'dev'\n","test['fold'] = 'test'\n","df = pd.concat([train, dev, test])\n","df['label'] = df.Class.apply(lambda x: 'Metaphor' if x ==1 else 'Non-metaphor')\n","df['text'] = df.text.apply(' '.join)\n","df.to_csv('./drive/MyDrive/rscf/wiktionary/wiktionary_verb_examples_full.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1655200065645,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"GXMWQECSekj9"},"outputs":[],"source":["#python3 $EDGE_CODE xlm-roberta-base lcc_ru_ru 0\n","#DeepPavlov/rubert-base-cased-conversational\n","model_checkpoint = 'DeepPavlov/rubert-base-cased-conversational'\n","my_dataset_info = dataset_info_dict['lcc+yulia_rusidio']\n","# my_dataset_info_2 = dataset_info_dict[(sys.argv[2]).split('-')[1]]\n","SEED = 0\n","SEQ2SEQ_MODEL = \"t5\" in model_checkpoint or \"pegasus\" in model_checkpoint or \"bart\" in model_checkpoint\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","set_seed(SEED)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2583,"status":"ok","timestamp":1655201016754,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"8gzxork9mP9R","outputId":"cc91309e-9354-40f2-bfa5-49b9bde94f5a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["if \"glove\" in model_checkpoint:\n","    model = AutoModel.from_pretrained(\"bert-base-uncased\")\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True, do_lower_case=False)\n","    tokenizer.padding_side = 'right'\n","    model = AutoModel.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"elapsed":719,"status":"ok","timestamp":1655201110148,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"Tnk-PVEVf0Vv","outputId":"2217ab8d-9eaa-4a0d-84c7-8eceac8c0d65"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n    def json_to_df(self, csv_path, to_sentence_span=False):\\n        pre_processes = [self.lcc_preprocess]\\n        texts = list(dataset[\\'text\\'])\\n        labels = []\\n        cache_ids = []\\n        spans = []\\n        for idx, text in enumerate(texts):\\n            if self.cache_last_hashable_input != repr(text):\\n                self.cache_last_hashable_input = repr(text)\\n                self.global_cache_counter += 1\\n            \\n            cache_ids.append(self.global_cache_counter)\\n\\n            \\n            if \"lcc\" in csv_path:\\n                labels.append(\\'1\\' if dataset[\\'label\\'][idx]==\\'Metaphor\\' else \\'0\\')\\n            if \"trofi\" in csv_path:\\n                labels.append(\\'1\\' if dataset[\\'label\\'][idx]==\\'nonliteral\\' else \\'0\\')\\n            if \"vua\" in csv_path:\\n                labels.append(\\'1\\' if dataset[\\'label\\'][idx]==1 else \\'0\\')\\n\\n            span_indices = dataset[\\'span1\\'][idx]\\n            spans.append([\\n                                     int(span_indices.split(\\',\\')[0].split(\\'[\\')[1]),\\n                                     int(span_indices.split(\\',\\')[1].split()[0].split(\\']\\')[0])\\n            ])\\n        \\n        dataset[\\'label\\'] = labels\\n        dataset[\\'cache_id\\'] = cache_ids\\n        dataset[\\'span1\\'] = spans\\n        return dataset\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}],"source":["\"\"\"# Prepare Dataset & Spans\"\"\"\n","\n","# model.save_pretrained(model_checkpoint)\n","# tokenizer.save_pretrained(model_checkpoint)\n","\n","class Utils:\n","    def one_hot(idx, length):\n","        import numpy as np\n","        o = np.zeros(length, dtype=np.int8)\n","        o[idx] = 1\n","        return o\n","\n","class Dataset_handler:\n","    def __init__(self, dataset_info: Dataset_info, selection = 'majority'):\n","        self.dataset = datasets.DatasetDict()\n","        self.tokenized_dataset = None\n","        self.dataset_info = dataset_info\n","        self.labels_list = None\n","        self.selection = selection\n","        # CACHE\n","        self.global_cache_counter = 0\n","        self.cache_last_hashable_input = \"\"\n","        \n","        if dataset_info.dataset_name == \"lcc_lcc_lcc\":\n","            frac = 1\n","            self.csv_to_dataset('./drive/MyDrive/metaphor-psycho/plm probing/ru/train.csv', data_type=\"train\", fraction = frac)\n","            self.csv_to_dataset('./drive/MyDrive/metaphor-psycho/plm probing/ru/dev.csv', data_type=\"dev\", fraction = frac)\n","            self.csv_to_dataset('./drive/MyDrive/metaphor-psycho/plm probing/ru/test.csv', data_type=\"test\", fraction = frac)\n","\n","        elif dataset_info.dataset_name == \"yulia_yulia_yulia\":\n","            frac = 1\n","            self.yulia_to_dataset('./drive/MyDrive/metaphor-psycho/verbs_with_wfs_full.csv', data_type=\"all\", fraction = frac)\n","        elif dataset_info.dataset_name == \"wiktionary_wiktionary_wiktionary\":\n","            frac = 1\n","            self.yulia_to_dataset('./drive/MyDrive/rscf/wiktionary/wiktionary_verb_examples_full.csv', data_type=\"all\", fraction = frac)\n","        elif dataset_info.dataset_name == \"manual\":\n","            frac = 1\n","            f = open(\"./manual_dataset.json\", \"w\")\n","            f.write('{\"text\": \"' + dataset_info.manual_text + '\", \"targets\": [{\"span1\": [0, 0], \"label\": \"' + my_dataset_handler.labels_list[0] + '\"}]}')\n","            f.write('\\n{\"text\": \"' + dataset_info.manual_text + '\", \"targets\": [{\"span1\": [0, 0], \"label\": \"' + my_dataset_handler.labels_list[1] + '\"}]}')\n","            f.close()\n","            self.json_to_dataset('./manual_dataset.json', data_type=\"train\", fraction = frac, to_sentence_span=True)\n","            self.json_to_dataset('./manual_dataset.json', data_type=\"dev\", fraction = frac, to_sentence_span=True)\n","            self.json_to_dataset('./manual_dataset.json', data_type=\"test\", fraction = frac, to_sentence_span=True)\n","        else:\n","            #throw(\"Error: Unkown dataset name!\")\n","            infos = dataset_info.dataset_name.split('_')\n","            frac=1\n","            for i, fold in enumerate(['train', 'dev', 'test']):\n","              if '+' in infos[i]:\n","                datas = []\n","                for info in infos[i].split('+'):\n","                  datas.append(self.any_to_dataset(info, fold=fold))\n","                self.dataset[fold] = datasets.concatenate_datasets(datas)\n","              else:\n","                self.any_to_dataset(infos[i], fold=fold)\n","\n","        print(\"⌛ Tokenizing Dataset and Adding One Hot Representation of Labels\")\n","        self.tokenized_dataset = self.tokenize_input_and_one_hot_labels(self.dataset)\n","        # self.tokenized_dataset = self.tokenize_dataset(self.dataset)\n","        # print(\"⌛ Adding One Hot Representation of Labels\")\n","        # self.tokenized_dataset = self.one_hot_dataset_labels(self.tokenized_dataset)\n","        \n","\n","    # Private:\n","    def merge_files(self, file_addresses: [], output_address: str):\n","        data = \"\"\n","        for file_address in file_addresses:\n","            with open(file_address) as fp:\n","                data += fp.read()\n","        with open (output_address, 'w') as fp:\n","            fp.write(data)\n","\n","    def any_to_dataset(self, any, fold=\"train\", frac=1):\n","      if any == 'lcc':\n","        return self.csv_to_dataset('./drive/MyDrive/metaphor-psycho/plm probing/ru/' + fold +'.csv', data_type=fold, fraction = frac)\n","      elif any == 'yulia':\n","        return self.yulia_to_dataset('./drive/MyDrive/metaphor-psycho/verbs_with_wfs_full.csv', data_type=fold, fraction = frac)\n","      elif any == 'wiktionary':\n","        return self.yulia_to_dataset('./drive/MyDrive/rscf/wiktionary/wiktionary_verb_examples_full.csv', data_type=fold, fraction = frac)\n","      elif any == 'rusidio':\n","        return self.rusidio_to_dataset('./drive/MyDrive/metaphor-psycho/metaphor_annotation_fpi/split1/', data_type=fold)\n","\n","    def csv_to_dataset(self, csv_path, data_type=\"train\", fraction=1):\n","      self.dataset[data_type] = datasets.Dataset.from_pandas(pd.read_csv(csv_path,converters={\"span1\": literal_eval}))\n","      return self.dataset[data_type]\n","    def yulia_to_dataset(self, csv_path, data_type=\"train\", fraction=1):\n","      df = pd.read_csv(csv_path, converters={\"span1\": literal_eval}, index_col=0)\n","      '''verbs = {}\n","      verbs['train'] = ['бомбардировать', 'доить', 'греть', 'очертить', 'пилить', 'причесать', 'распылять',\n","            'разбавлять', 'съедать', 'трубить', 'уколоть', 'выкраивать', 'взорвать', 'жонглировать']\n","      verbs['dev'] = ['зажигать', 'нападать']\n","      verbs['test'] = ['утюжить', 'отрубить', 'подхватывать', 'взвесить']\n","      def get_spans(sent, wordform):\n","        try:\n","          s = sent.split().index(wordform.split('\\'')[1])\n","          return [s, s+1]\n","        except:\n","          print(sent)\n","      def get_folds(x):\n","        for fold, vbs in verbs.items():\n","          if x in vbs:\n","            return fold\n","      df['fold'] = df.verblemma.apply(get_folds)      \n","      df['span1'] = df.apply(lambda x: get_spans(x.sent, x.wordforms), axis=1)\n","      df['label'] = df.Class.apply(lambda x: 'Metaphor' if x ==1 else 'Non-metaphor')\n","      '''\n","      if not ('text' in df.columns):\n","        df['text'] = df['sent']\n","      df['fold'] = df.fold.apply(lambda x: 'dev' if x == 'val' else x )\n","      if data_type==\"all\":\n","        for data_type in ['train', 'dev', 'test']:\n","          self.dataset[data_type] = datasets.Dataset.from_pandas(df[['text', 'span1', 'label']][df.fold == data_type])\n","      else:\n","          self.dataset[data_type] = datasets.Dataset.from_pandas(df[['text', 'span1', 'label']][df.fold == data_type])\n","      \n","      return self.dataset[data_type]\n","    def rusidio_to_dataset(self, foo, data_type='test'):\n","      selection = self.selection\n","      fns = os.listdir(foo)\n","      dfs = []\n","      def get_spans(sent, wordform):\n","        s = sent.split()\n","        try:\n","          s = s.index(wordform)\n","        except:\n","          print(wordform, '\\t', s)\n","        return [s, s+1]\n","      if selection == 'majority':\n","        def maj(met_labels):\n","          if sum(met_labels) >= len(met_labels)/2.:\n","            return 'Metaphor'\n","          else:\n","            return 'Non-metaphor'\n","      for fn in fns:\n","        df = pd.read_excel(foo+fn, index_col=0)\n","        df['text_id'] = fn[:-5]\n","        if ('Elena_metaphor' in df.columns) and ('Victoria_metaphor' in df.columns) and ('Polina_metaphor' in df.columns):\n","          if selection == 'agree3':\n","            dfs.append(df[(df.Elena_metaphor == df.Victoria_metaphor) & (df.Victoria_metaphor == df.Polina_metaphor)])\n","          elif selection == 'agree2':\n","            dfs.append(df[df.Victoria_metaphor == df.Polina_metaphor])\n","          else:\n","             dfs.append(df)\n","      df = pd.concat(dfs)\n","      df['span1'] = df.apply(lambda x: get_spans(x.sent, x.verb), axis=1)\n","      df['text'] = df.sent\n","      #df['label'] = df.Elena_metaphor.apply(lambda x: 'Metaphor' if x == 1. else 'Non-metaphor')\n","      if selection.startswith('agree'):\n","        df['label'] = df.Polina_metaphor.apply(lambda x: 'Metaphor' if x == 1. else 'Non-metaphor')\n","      elif selection == 'majority':\n","        df['label'] = df.apply(lambda x: maj([x.Victoria_metaphor, x.Polina_metaphor, x.Elena_metaphor]), axis=1)\n","      else:\n","        df['label'] = df[selection +'_metaphor'].apply(lambda x: 'Metaphor' if x == 1. else 'Non-metaphor')\n","      if data_type==\"test\":\n","        self.dataset[data_type] = datasets.Dataset.from_pandas(df[['text_id', 'text', 'span1', 'label', 'verb', 'Polina_metaphor', 'Victoria_metaphor', 'Elena_metaphor']])\n","      return self.dataset[data_type]\n","    '''\n","    def json_to_dataset(self, json_path, data_type=\"train\", fraction=1, ignore_classes=[], keep_order=False, sample_from_head=False, to_sentence_span=False):\n","        data_df = self.json_to_df(json_path, to_sentence_span)\n","        data_df = data_df[~data_df[\"label\"].isin(ignore_classes)]\n","        if sample_from_head:\n","            data_df = data_df.head(int(len(data_df) * fraction))\n","        else:\n","            if keep_order:\n","                data_df = data_df.sample(frac=fraction, random_state=SEED).sort_index().reset_index(drop=True)\n","            else:\n","                data_df = data_df.sample(frac=fraction, random_state=SEED).reset_index(drop=True)\n","        self.dataset[data_type] = datasets.Dataset.from_pandas(data_df)\n","        return self.dataset\n","    '''    \n","    def tokenize_input_and_one_hot_labels(self, dataset):\n","        train_df = pd.DataFrame(dataset[\"train\"][\"label\"], columns=['label'])\n","        dev_df = pd.DataFrame(dataset[\"dev\"][\"label\"], columns=['label'])\n","        test_df = pd.DataFrame(dataset[\"test\"][\"label\"], columns=['label'])\n","        self.labels_list = list(set(train_df[\"label\"].unique()).union\n","                               (set(dev_df[\"label\"].unique())).union\n","                               (set(test_df[\"label\"].unique())))\n","        self.label_to_index = dict()\n","        for idx, l in enumerate(self.labels_list):\n","            self.label_to_index[l] = idx\n","        \n","        if \"glove\" in model_checkpoint or \"elmo\" in model_checkpoint:\n","            tokenized_one_hot_dataset = dataset.map(tokenize_and_one_hot_glove,\n","                                                    fn_kwargs={\"label_to_index\": self.label_to_index,\n","                                                            \"labels_len\": len(self.label_to_index),\n","                                                            \"one_hot_func\": Utils.one_hot,\n","                                                            \"num_of_spans\": self.dataset_info.num_of_spans\n","                                                            },\n","                                                    batched=False,\n","                                                    num_proc=None)\n","        else:\n","            tokenized_one_hot_dataset = dataset.map(tokenize_and_one_hot,\n","                                                    fn_kwargs={\"label_to_index\": self.label_to_index,\n","                                                            \"labels_len\": len(self.label_to_index),\n","                                                            \"tokenizer\": tokenizer,\n","                                                            \"one_hot_func\": Utils.one_hot,\n","                                                            \"num_of_spans\": self.dataset_info.num_of_spans\n","                                                            },\n","                                                    batched=False,\n","                                                    num_proc=None)\n","        return tokenized_one_hot_dataset\n","\n","    # Preprocesses\n","    def lcc_preprocess(self, target, instance, json_path):\n","        # if \"lcc\" in self.dataset_info.dataset_name.split('-')[0] and \"src\" not in self.dataset_info.dataset_name:\n","        if \"lcc\" in json_path:    \n","            target[\"label\"] = float(target[\"label\"])\n","            if 0.0 <= target[\"label\"] < 0.5:\n","                # target[\"label\"] = \"Non-metaphor\"\n","                target[\"label\"] = 0\n","            elif 1.5 < target[\"label\"] <= 3.0:\n","                # target[\"label\"] = \"Metaphor\"\n","                target[\"label\"] = 1\n","            else:\n","                return None, None\n","        if \"trofi\" in json_path:    \n","            if target[\"label\"]=='nonliteral':\n","                target[\"label\"] = 1\n","            elif target[\"label\"]=='literal':\n","                target[\"label\"] = 0\n","    \n","    def lcc_src_concept_preprocess(self, target, instance):\n","        if self.dataset_info.dataset_name == \"lcc_src_concept\":\n","            target[\"span1\"] = target[\"span2\"]\n","            score = float(target[\"score\"])\n","            if score >= 2:\n","                return target, instance\n","            else:\n","                return None, None\n","        return target, instance\n","\n","    def hatexplain_preprocess(self, target, instance):\n","        return target, instance\n","\n","    def hatexplain_fullspan_preprocess(self, target, instance):\n","        if self.dataset_info.dataset_name == \"hatexplain-fullspan\":\n","            instance[\"text\"] = re.sub(r'[^A-Za-z0-9 ]+', '', instance[\"text\"])  # Alphanumeric + Space\n","        return target, instance\n","    \n","    def lcc_src_target_concept_preprocess(self, target, instance):\n","        if self.dataset_info.dataset_name == \"lcc_src_target_concept\":\n","            target[\"label\"] = \"(\" + target[\"label\"] + \",\" + instance[\"targetConcept\"] + \")\"\n","        return target, instance\n","'''\n","    def json_to_df(self, csv_path, to_sentence_span=False):\n","        pre_processes = [self.lcc_preprocess]\n","        texts = list(dataset['text'])\n","        labels = []\n","        cache_ids = []\n","        spans = []\n","        for idx, text in enumerate(texts):\n","            if self.cache_last_hashable_input != repr(text):\n","                self.cache_last_hashable_input = repr(text)\n","                self.global_cache_counter += 1\n","            \n","            cache_ids.append(self.global_cache_counter)\n","\n","            \n","            if \"lcc\" in csv_path:\n","                labels.append('1' if dataset['label'][idx]=='Metaphor' else '0')\n","            if \"trofi\" in csv_path:\n","                labels.append('1' if dataset['label'][idx]=='nonliteral' else '0')\n","            if \"vua\" in csv_path:\n","                labels.append('1' if dataset['label'][idx]==1 else '0')\n","\n","            span_indices = dataset['span1'][idx]\n","            spans.append([\n","                                     int(span_indices.split(',')[0].split('[')[1]),\n","                                     int(span_indices.split(',')[1].split()[0].split(']')[0])\n","            ])\n","        \n","        dataset['label'] = labels\n","        dataset['cache_id'] = cache_ids\n","        dataset['span1'] = spans\n","        return dataset\n","'''"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["bb5b2db2c2e54251ad9e368fc926984e","02df26e0650d49b7baaeb15329e18b60","41834969de2e4d6b9b32915236bff747","86c72db7de3b4836a6a98a7cdf707765","1c9bcdfb96034b6d8965b55a760fc3b0","a24fdd35a114420f97107672033c8bb0","05e2dc03851e497c8e1e155fbf9558b9","39c86f20913e43d988bfbde42dae8a30","6494d9c8ce704557b06dd7a2555aa674","22e9c73a281f474a8b7b48c8f26a3643","9cc41257366043e2a6612f0c902d9df0","63b71bd447384968a8df6a98752826aa","93275ab405aa4dddb6cf3c3d948b5e9f","4db2a3b437294b5db0ef60115d1064ca","8b045cd7fc7543bb89c1b5b05462f766","1c253effd6204546803642d69647a697","6a2373d8db2b4f3899a20a1b11e1c924","4bf1010f87ec400c999ff1ccd085f3a6","caaed7fcadf745a38813734552013de7","ce792c4ee4b54f5c8ab09495d22b8447","0570ddb2bf4a451ba3ae3e736a8b8fc8","c8662a062cc64df8b4c796ba23662342","4cc1c2827ac64268baac34caf2ea3e2c","57b5d8eb41654397be4149e8b84acbea","acff480ff9c94255b7c5790e7fc12724","b257df316f76412d83406f012ae0615a","6c15a77f73ff4bff84bf6ba4856a07d3","cc5e0a303123432ab947b25b7eda348e","9220230c7fcc4430a7e7c5991a45d7c2","6c13a323dcfe4f0290722f304d399d4f","2ae780be3f26438987410c75a0270693","a520d4f1990a4e139119ab19782304f0","b6382bee21ee43e0b1cfc59b5d06bfc7"]},"executionInfo":{"elapsed":22055,"status":"ok","timestamp":1655201133935,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"jNXEpwvDf9sB","outputId":"3b52c551-f60e-4680-f926-6eede5c20554"},"outputs":[{"output_type":"stream","name":"stdout","text":["⌛ Tokenizing Dataset and Adding One Hot Representation of Labels\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/17387 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5b2db2c2e54251ad9e368fc926984e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2355 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63b71bd447384968a8df6a98752826aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2643 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cc1c2827ac64268baac34caf2ea3e2c"}},"metadata":{}}],"source":["def tokenize_and_one_hot_glove(examples, **fn_kwargs):\n","    # tokenize and align spans\n","    one_hot_func = fn_kwargs[\"one_hot_func\"]\n","    num_of_spans = fn_kwargs[\"num_of_spans\"]\n","    tokenized_inputs = {\"text\": examples[\"text\"].lower().split()}\n","\n","    tokenized_inputs[\"span1\"] = [examples[\"span1\"][0], examples[\"span1\"][1]]\n","    tokenized_inputs[\"span1_len\"] = tokenized_inputs[\"span1\"][1] - tokenized_inputs[\"span1\"][0]\n","    if num_of_spans == 2:\n","        tokenized_inputs[\"span2\"] = [examples[\"span2\"][0], examples[\"span2\"][1]]\n","        tokenized_inputs[\"span2_len\"] = tokenized_inputs[\"span2\"][1] - tokenized_inputs[\"span2\"][0]\n","    # One hot\n","    label_to_index = fn_kwargs[\"label_to_index\"]\n","    labels_len = fn_kwargs[\"labels_len\"]\n","    tokenized_inputs[\"one_hot_label\"] = one_hot_func(label_to_index[examples[\"label\"]], labels_len)\n","    return tokenized_inputs\n","\n","cached_tokenized_input = {}\n","cached_onehot = {}\n","def tokenize_and_one_hot(examples, **fn_kwargs):\n","    # tokenize and align spans\n","    thread_tokenizer = fn_kwargs[\"tokenizer\"]\n","    one_hot_func = fn_kwargs[\"one_hot_func\"]\n","    num_of_spans = fn_kwargs[\"num_of_spans\"]\n","    \n","    if repr(examples[\"text\"]) in cached_tokenized_input:\n","        tokenized_inputs = cached_tokenized_input[repr(examples[\"text\"])]\n","    else:\n","        tokenized_inputs = thread_tokenizer(examples[\"text\"].split(), is_split_into_words=True)  # Must be splitted for tokenizer to word_ids works fine. (test e-mail!)\n","        cached_tokenized_input[repr(examples[\"text\"])] = tokenized_inputs\n","    def align_span(word_ids, start_word_id, end_word_id):\n","        span = [0, 0]\n","        if start_word_id not in word_ids:\n","            print(\"Warning: There is no\", start_word_id, \"in\", word_ids, examples[\"text\"].split(), examples[\"label\"])\n","            print(start_word_id)\n","            start_word_id -= 1\n","        span[0] = word_ids.index(start_word_id)  # First occurance\n","        if end_word_id - 1 not in word_ids[::-1]:\n","            print(\"Warning: There is no\", end_word_id - 1, \"in\", word_ids, examples[\"text\"].split(), examples[\"label\"])\n","            end_word_id -= 1\n","        span[1] = len(word_ids) - 1 - word_ids[::-1].index(end_word_id - 1) + 1  # Last occurance (+1 for open range)\n","        return span\n","\n","    word_ids = tokenized_inputs.word_ids()\n","    tokenized_inputs[\"span1\"] = align_span(word_ids, examples[\"span1\"][0], examples[\"span1\"][1])\n","    tokenized_inputs[\"span1_len\"] = tokenized_inputs[\"span1\"][1] - tokenized_inputs[\"span1\"][0]\n","    if num_of_spans == 2:\n","        tokenized_inputs[\"span2\"] = align_span(word_ids, examples[\"span2\"][0], examples[\"span2\"][1])\n","        tokenized_inputs[\"span2_len\"] = tokenized_inputs[\"span2\"][1] - tokenized_inputs[\"span2\"][0]\n","    # One hot\n","    label_to_index = fn_kwargs[\"label_to_index\"]\n","    labels_len = fn_kwargs[\"labels_len\"]\n","    if examples[\"label\"] in cached_onehot:\n","        tokenized_inputs[\"one_hot_label\"] = cached_onehot[examples[\"label\"]]\n","    else:\n","        tokenized_inputs[\"one_hot_label\"] = one_hot_func(label_to_index[examples[\"label\"]], labels_len)\n","        cached_onehot[examples[\"label\"]] = tokenized_inputs[\"one_hot_label\"]\n","    return tokenized_inputs\n","\n","my_dataset_handler = Dataset_handler(my_dataset_info, selection = 'Polina');"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1655201137722,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"pm7ENBbopk_r","outputId":"0e006f11-9fae-4dd2-d2b2-a6bb8191f61f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                text     span1         label  \\\n","0  розваровываются богатства россии а капитал выв...    [6, 7]  Non-metaphor   \n","1  Тем более, прецедент в историиуже есть – прихо...  [10, 11]      Metaphor   \n","2  д ... . Традиционные орнаменты на русских наро...  [22, 23]      Metaphor   \n","\n","  __index_level_0__                                          input_ids  \\\n","0              None  [101, 9187, 51202, 355, 2956, 36751, 9965, 301...   \n","1              None  [101, 4044, 1377, 128, 60598, 340, 3354, 15806...   \n","2              None  [101, 348, 132, 132, 132, 132, 28643, 7113, 77...   \n","\n","                                      token_type_ids  \\\n","0         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n","1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","\n","                                      attention_mask  span1_len one_hot_label  \n","0         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]          1        [1, 0]  \n","1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          1        [0, 1]  \n","2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          1        [0, 1]  "],"text/html":["\n","  <div id=\"df-81cb07cb-ea11-4b83-bdab-b3e3fd4e99ad\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>span1</th>\n","      <th>label</th>\n","      <th>__index_level_0__</th>\n","      <th>input_ids</th>\n","      <th>token_type_ids</th>\n","      <th>attention_mask</th>\n","      <th>span1_len</th>\n","      <th>one_hot_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>розваровываются богатства россии а капитал выв...</td>\n","      <td>[6, 7]</td>\n","      <td>Non-metaphor</td>\n","      <td>None</td>\n","      <td>[101, 9187, 51202, 355, 2956, 36751, 9965, 301...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n","      <td>1</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Тем более, прецедент в историиуже есть – прихо...</td>\n","      <td>[10, 11]</td>\n","      <td>Metaphor</td>\n","      <td>None</td>\n","      <td>[101, 4044, 1377, 128, 60598, 340, 3354, 15806...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>1</td>\n","      <td>[0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>д ... . Традиционные орнаменты на русских наро...</td>\n","      <td>[22, 23]</td>\n","      <td>Metaphor</td>\n","      <td>None</td>\n","      <td>[101, 348, 132, 132, 132, 132, 28643, 7113, 77...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>1</td>\n","      <td>[0, 1]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81cb07cb-ea11-4b83-bdab-b3e3fd4e99ad')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-81cb07cb-ea11-4b83-bdab-b3e3fd4e99ad button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-81cb07cb-ea11-4b83-bdab-b3e3fd4e99ad');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                      text_id  \\\n","0  1RP2_nan_ж_0_повествование   \n","1  1RP2_nan_ж_0_повествование   \n","2  1RP2_nan_ж_0_повествование   \n","3  1RP2_nan_ж_0_повествование   \n","4  1RP2_nan_ж_0_повествование   \n","\n","                                                text     span1         label  \\\n","0  Вот уже прошло двадцать четыре дня со дня моег...    [3, 4]      Metaphor   \n","1  Первое время было тяжело , так как сложно жить...   [9, 10]  Non-metaphor   \n","2  Первое время было тяжело , так как сложно жить...  [16, 17]  Non-metaphor   \n","3  Поначалу учеба всегда кажется легкой , нет так...    [4, 5]  Non-metaphor   \n","4  Хотя у меня есть задолженности по учебе и их я...  [11, 12]  Non-metaphor   \n","\n","      verb  Polina_metaphor  Victoria_metaphor  Elena_metaphor  \\\n","0   прошло              1.0                1.0             1.0   \n","1     жить              0.0                0.0             0.0   \n","2     ждут              0.0                0.0             0.0   \n","3  кажется              0.0                0.0             0.0   \n","4  пытаюсь              0.0                0.0             0.0   \n","\n","   __index_level_0__                                          input_ids  \\\n","0                0.0  [101, 1337, 1034, 3554, 11839, 4312, 2988, 850...   \n","1                1.0  [101, 15217, 1210, 1035, 4794, 128, 927, 879, ...   \n","2                2.0  [101, 15217, 1210, 1035, 4794, 128, 927, 879, ...   \n","3                3.0  [101, 43082, 77612, 1583, 1965, 33033, 128, 10...   \n","4                4.0  [101, 2630, 352, 1021, 999, 35869, 797, 70872,...   \n","\n","                                      token_type_ids  \\\n","0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n","1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n","\n","                                      attention_mask  span1_len one_hot_label  \n","0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]          1        [0, 1]  \n","1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          1        [1, 0]  \n","2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          1        [1, 0]  \n","3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          1        [1, 0]  \n","4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]          1        [1, 0]  "],"text/html":["\n","  <div id=\"df-7c35ae55-293f-477e-a75c-eab96cd191ff\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>span1</th>\n","      <th>label</th>\n","      <th>verb</th>\n","      <th>Polina_metaphor</th>\n","      <th>Victoria_metaphor</th>\n","      <th>Elena_metaphor</th>\n","      <th>__index_level_0__</th>\n","      <th>input_ids</th>\n","      <th>token_type_ids</th>\n","      <th>attention_mask</th>\n","      <th>span1_len</th>\n","      <th>one_hot_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1RP2_nan_ж_0_повествование</td>\n","      <td>Вот уже прошло двадцать четыре дня со дня моег...</td>\n","      <td>[3, 4]</td>\n","      <td>Metaphor</td>\n","      <td>прошло</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>[101, 1337, 1034, 3554, 11839, 4312, 2988, 850...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n","      <td>1</td>\n","      <td>[0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1RP2_nan_ж_0_повествование</td>\n","      <td>Первое время было тяжело , так как сложно жить...</td>\n","      <td>[9, 10]</td>\n","      <td>Non-metaphor</td>\n","      <td>жить</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>[101, 15217, 1210, 1035, 4794, 128, 927, 879, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>1</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1RP2_nan_ж_0_повествование</td>\n","      <td>Первое время было тяжело , так как сложно жить...</td>\n","      <td>[16, 17]</td>\n","      <td>Non-metaphor</td>\n","      <td>ждут</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>[101, 15217, 1210, 1035, 4794, 128, 927, 879, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>1</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1RP2_nan_ж_0_повествование</td>\n","      <td>Поначалу учеба всегда кажется легкой , нет так...</td>\n","      <td>[4, 5]</td>\n","      <td>Non-metaphor</td>\n","      <td>кажется</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>[101, 43082, 77612, 1583, 1965, 33033, 128, 10...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>1</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1RP2_nan_ж_0_повествование</td>\n","      <td>Хотя у меня есть задолженности по учебе и их я...</td>\n","      <td>[11, 12]</td>\n","      <td>Non-metaphor</td>\n","      <td>пытаюсь</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>[101, 2630, 352, 1021, 999, 35869, 797, 70872,...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n","      <td>1</td>\n","      <td>[1, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c35ae55-293f-477e-a75c-eab96cd191ff')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7c35ae55-293f-477e-a75c-eab96cd191ff button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7c35ae55-293f-477e-a75c-eab96cd191ff');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["idx = 629\n","DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'span1', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'span1_len', 'one_hot_label'],\n","        num_rows: 17387\n","    })\n","    dev: Dataset({\n","        features: ['text', 'span1', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'span1_len', 'one_hot_label'],\n","        num_rows: 2355\n","    })\n","    test: Dataset({\n","        features: ['text_id', 'text', 'span1', 'label', 'verb', 'Polina_metaphor', 'Victoria_metaphor', 'Elena_metaphor', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'span1_len', 'one_hot_label'],\n","        num_rows: 2643\n","    })\n","})\n","Original Spans: {'text_id': '56RP2_nan_ж_0_повествование', 'text': 'Так много всего интересного произошло за последний месяц .', 'span1': [4, 5], 'label': 'Non-metaphor', 'verb': 'произошло', 'Polina_metaphor': 0.0, 'Victoria_metaphor': 0.0, 'Elena_metaphor': 0.0, '__index_level_0__': 0.0}\n","Tokenized Spans: {'text_id': '56RP2_nan_ж_0_повествование', 'text': 'Так много всего интересного произошло за последний месяц .', 'span1': [5, 6], 'label': 'Non-metaphor', 'verb': 'произошло', 'Polina_metaphor': 0.0, 'Victoria_metaphor': 0.0, 'Elena_metaphor': 0.0, '__index_level_0__': 0.0, 'input_ids': [101, 1272, 1278, 1383, 14184, 5576, 823, 4958, 3569, 132, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'span1_len': 1, 'one_hot_label': [1, 0]}\n","['[CLS]', 'Так', 'много', 'всего', 'интересного', 'произошло', 'за', 'последний', 'месяц', '.', '[SEP]']\n","span1: 5 6 ['произошло']\n","label: Non-metaphor\n","Non-metaphor    2021\n","Metaphor         622\n","['Non-metaphor', 'Metaphor']\n","|Labels| = 2\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x648 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Check\n","rnd_idx = np.random.randint(1000)\n","# rnd_idx = 58000\n","part = \"test\"\n","display(pd.DataFrame(my_dataset_handler.tokenized_dataset['train'][0:3]))\n","display(pd.DataFrame(my_dataset_handler.tokenized_dataset['test'][0:5]))\n","print(\"idx =\", rnd_idx)\n","print(my_dataset_handler.tokenized_dataset)\n","print(\"Original Spans:\", my_dataset_handler.dataset[part][rnd_idx])\n","print(\"Tokenized Spans:\", my_dataset_handler.tokenized_dataset[part][rnd_idx])\n","if \"glove\" in model_checkpoint or \"elmo\" in model_checkpoint:\n","    test_tokens = my_dataset_handler.tokenized_dataset[part][rnd_idx][\"text\"]\n","else:\n","    test_tokens = tokenizer.convert_ids_to_tokens(my_dataset_handler.tokenized_dataset[part][rnd_idx][\"input_ids\"])\n","print(test_tokens)\n","\n","s10, s11 = my_dataset_handler.tokenized_dataset[part][rnd_idx][\"span1\"][0], my_dataset_handler.tokenized_dataset[part][rnd_idx][\"span1\"][-1]\n","print(\"span1:\", s10, s11, test_tokens[s10:s11])\n","if my_dataset_info.num_of_spans == 2:\n","    s20, s21 = my_dataset_handler.tokenized_dataset[part][rnd_idx][\"span2\"][0], my_dataset_handler.tokenized_dataset[part][rnd_idx][\"span2\"][-1]\n","    print(\"span2:\", s20, s21, test_tokens[s20:s21])\n","print(\"label:\", my_dataset_handler.tokenized_dataset[part][rnd_idx][\"label\"])\n","\n","stats = pd.DataFrame(my_dataset_handler.tokenized_dataset[part][\"label\"], columns=['label'])[\"label\"].value_counts()\n","print(stats.to_string())\n","print(list(stats.index))\n","print(\"|Labels| =\", len(stats))\n","stats.plot(kind='barh', color=\"green\", figsize=(10, 9));\n"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":689,"status":"ok","timestamp":1655201140807,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"PKv51iuNglQW"},"outputs":[],"source":["\"\"\"# Edge Probe\"\"\"\n","\n","class SpanRepr(ABC, nn.Module):\n","    \"\"\"Abstract class describing span representation.\"\"\"\n","\n","    def __init__(self, input_dim, use_proj=False, proj_dim=256):\n","        super(SpanRepr, self).__init__()\n","        self.input_dim = input_dim  # embedding dim or proj dim\n","        self.proj_dim = proj_dim\n","        self.use_proj = use_proj\n","\n","    @abstractmethod\n","    def forward(self, spans, attention_mask):\n","        \"\"\" \n","        input:\n","            spans: [batch_size, layers, span_max_len, proj_dim/embedding_dim] ~ [32, 13, 4, 256]\n","            attention_mask: [batch_size, span_max_len] ~ [32, 4]\n","        returns:\n","            [32, 13, 256]\n","        \"\"\"\n","        raise NotImplementedError\n","\n","    def get_input_dim(self):\n","        return self.input_dim\n","\n","class MaxSpanRepr(SpanRepr, nn.Module):\n","    \"\"\"Class implementing the max-pool span representation.\"\"\"\n","\n","    def forward(self, spans, attention_mask):\n","        span_masks_shape = attention_mask.shape\n","        span_masks = attention_mask.reshape(\n","            span_masks_shape[0],\n","            1,\n","            span_masks_shape[1],\n","            1\n","        ).expand_as(spans)\n","        attention_spans = spans * span_masks - 1e10 * (1 - span_masks)\n","\n","        max_span_repr, max_idxs = torch.max(attention_spans, dim=-2)\n","        return max_span_repr\n","\n","class AttnSpanRepr(SpanRepr, nn.Module):\n","    \"\"\"Class implementing the attention-based span representation.\"\"\"\n","\n","    def __init__(self, input_dim, use_proj=False, proj_dim=256, use_endpoints=False):\n","        \"\"\"If use_endpoints is true then concatenate the end points to attention-pooled span repr.\n","        Otherwise just return the attention pooled term. (use_endpoints Not Implemented)\n","        \"\"\"\n","        super(AttnSpanRepr, self).__init__(input_dim, use_proj=use_proj, proj_dim=proj_dim)\n","        self.use_endpoints = use_endpoints\n","        self.attention_params = nn.Linear(input_dim, 1)  # Learn a weight for each token: z(k)i = W(k)att e(k)i\n","        self.last_attention_wts = None\n","\n","    def forward(self, spans, attention_mask):\n","        \"\"\" \n","        input:\n","            spans: [batch_size, layers, span_max_len, proj_dim/embedding_dim] ~ [32, 13, 4, 256]\n","            attention_mask: [batch_size, span_max_len] ~ [32, 4]\n","        returns:\n","            [32, 13, 256]\n","        \"\"\"\n","        span_masks_shape = attention_mask.shape\n","        span_masks = attention_mask.reshape(\n","            span_masks_shape[0],\n","            1,\n","            span_masks_shape[1],\n","            1\n","        ).expand_as(spans)\n","        attn_mask = - 1e10 * (1 - span_masks)\n","\n","        attn_logits = self.attention_params(spans) + attn_mask  # Decreasing the attention of padded spans by -1e10\n","        attention_wts = nn.functional.softmax(attn_logits, dim=-2)\n","        attention_term = torch.sum(attention_wts * spans, dim=-2)\n","\n","        self.last_attention_wts = attention_wts   # Save for later analysis\n","\n","        return attention_term.float()\n","\n","def get_span_module(input_dim, method=\"max\", use_proj=False, proj_dim=256):\n","    \"\"\"Initializes the appropriate span representation class and returns the object.\n","    \"\"\"\n","    if method == \"avg\":\n","        return AvgSpanRepr(input_dim, use_proj=use_proj, proj_dim=proj_dim)\n","    elif method == \"max\":\n","        return MaxSpanRepr(input_dim, use_proj=use_proj, proj_dim=proj_dim)\n","    elif method == \"diff\":\n","        return DiffSpanRepr(input_dim, use_proj=use_proj, proj_dim=proj_dim)\n","    elif method == \"diff_sum\":\n","        return DiffSumSpanRepr(input_dim, use_proj=use_proj, proj_dim=proj_dim)\n","    elif method == \"endpoint\":\n","        return EndPointRepr(input_dim, use_proj=use_proj, proj_dim=proj_dim)\n","    elif method == \"coherent\":\n","        return CoherentSpanRepr(input_dim, use_proj=use_proj, proj_dim=proj_dim)\n","    elif method == \"coherent_original\":\n","        return CoherentOrigSpanRepr(input_dim, use_proj=use_proj, proj_dim=proj_dim)\n","    elif method == \"attn\":\n","        return AttnSpanRepr(input_dim, use_proj=use_proj, proj_dim=proj_dim)\n","    elif method == \"coref\":\n","        return AttnSpanRepr(input_dim, use_proj=use_proj, proj_dim=proj_dim, use_endpoints=True)\n","    else:\n","        raise NotImplementedError\n","\n","class Edge_probe_model(nn.Module):\n","    def __init__(self, num_of_spans, num_layers, input_span_len, embedding_dim, \n","                 num_classes, pool_method='max', use_proj=True, proj_dim=256, \n","                 hidden_dim=256, device='cuda', normalize_layers=False, use_cross_entropy=False):\n","        super(Edge_probe_model, self).__init__()\n","        self.device = device\n","        self.num_layers = num_layers\n","        self.num_classes = num_classes\n","        self.num_of_spans = num_of_spans\n","        self.weighing_params = nn.Parameter(torch.ones(self.num_layers))\n","        self.input_dim = embedding_dim * num_of_spans\n","        self.use_proj = use_proj\n","        self.proj_dim = proj_dim\n","        self.normalize_layers = normalize_layers\n","\n","        ## Projection\n","        if use_proj:\n","            # Apply a projection layer to output of pretrained models\n","            self.proj1 = nn.Linear(embedding_dim, proj_dim)\n","            if self.num_of_spans == 2:\n","                self.proj2 = nn.Linear(embedding_dim, proj_dim)\n","            # Update the input_dim\n","            self.input_dim = proj_dim * num_of_spans\n","\n","        ## Pooling\n","        self.pool_method = pool_method\n","        input_dim = proj_dim if use_proj else embedding_dim\n","        self.span1_pooling_net = get_span_module(input_dim, method=pool_method).to(device)\n","        if self.num_of_spans == 2:\n","            self.span2_pooling_net = get_span_module(input_dim, method=pool_method).to(device)\n","\n","        ## Classification\n","        label_net_list = [\n","            nn.Linear(self.input_dim, hidden_dim),\n","            nn.Tanh(),\n","            nn.LayerNorm(hidden_dim),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_dim, self.num_classes)        \n","        ]\n","        if use_cross_entropy:\n","            self.training_criterion = nn.CrossEntropyLoss()\n","        else:\n","            self.training_criterion = nn.BCELoss()\n","            label_net_list.append(nn.Sigmoid())\n","\n","        self.label_net = nn.Sequential(*label_net_list)\n","        self.optimizer = optim.Adam(self.parameters(), lr=LEARNING_RATE, weight_decay=0)\n","\n","    def forward(self, spans_torch_dict):\n","        span1_reprs = spans_torch_dict[\"span1\"]\n","        span1_attention_mask = spans_torch_dict[\"span1_attention_mask\"]\n","        if self.num_of_spans == 2:\n","            span2_reprs = spans_torch_dict[\"span2\"]\n","            span2_attention_mask = spans_torch_dict[\"span2_attention_mask\"]\n","        \n","        ## Projection\n","        if self.use_proj:\n","            span1_reprs = self.proj1(span1_reprs)\n","            if self.num_of_spans == 2:\n","                span2_reprs = self.proj2(span2_reprs)\n","        \n","        ## Pooling\n","        pooled_span1 = self.span1_pooling_net(span1_reprs, span1_attention_mask)\n","        if self.num_of_spans == 2:\n","            pooled_span2 = self.span2_pooling_net(span2_reprs, span2_attention_mask)\n","\n","        if self.normalize_layers:\n","            pooled_span1 = torch.nn.functional.normalize(pooled_span1, dim=-1)\n","            if self.num_of_spans == 2:\n","                pooled_span2 = torch.nn.functional.normalize(pooled_span2, dim=-1)\n","\n","        if self.num_of_spans == 2:\n","            output = torch.cat((pooled_span1, pooled_span2), dim=-1)\n","        elif self.num_of_spans == 1:\n","            output = pooled_span1\n","        # print(output.shape)  # torch.Size([32, 13, 512])\n","\n","        ## Mixing Weights\n","        wtd_encoded_repr = 0\n","        soft_weight = nn.functional.softmax(self.weighing_params, dim=0)\n","        for i in range(self.num_layers):\n","            wtd_encoded_repr += soft_weight[i] * output[:, i, :]\n","        output = wtd_encoded_repr\n","\n","        ## Classification\n","        pred_label = self.label_net(output)\n","        pred_label = torch.squeeze(pred_label, dim=-1)\n","        return pred_label\n","\n","    def summary(self, do_print=True):\n","        summary_str = str(self)\n","        pytorch_total_params = sum(p.numel() for p in self.parameters())\n","        pytorch_total_params_trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n","        summary_str += f\"\\n Total Parameters:     {pytorch_total_params}\"\n","        summary_str += f\"\\n Trainable Parameters: {pytorch_total_params_trainable}\"\n","        summary_str += f\"\\n Pool Method: {self.pool_method}\"\n","        summary_str += f\"\\n Projection: {self.use_proj}, {self.proj_dim}\"\n","        summary_str += f\"\\n normalize_layers: {self.normalize_layers}\"\n","        if do_print:\n","            print(summary_str)\n","        return summary_str\n"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":2849,"status":"ok","timestamp":1655201145245,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"pFqoS_UbnwuR"},"outputs":[],"source":["gpu_cache = dict()\n","ram_cache = dict()\n","class Trainer(ABC):\n","    \"\"\" Abstract Trainer Class \"\"\"\n","    def span_dict_to_device(self, spans_torch_dict, device=\"cuda\"):\n","        new_dict = copy.deepcopy(spans_torch_dict)\n","        new_dict[\"span1\"] = new_dict[\"span1\"].to(device)\n","        new_dict[\"span1_attention_mask\"] = new_dict[\"span1_attention_mask\"].to(device)\n","        if self.num_of_spans == 2:\n","            new_dict[\"span2\"] = new_dict[\"span2\"].to(device)\n","            new_dict[\"span2_attention_mask\"] = new_dict[\"span2_attention_mask\"].to(device)\n","        return new_dict\n","\n","    def prepare_batch_data(self, tokenized_dataset, start_idx, end_idx, pad=False, cache_prefix=None):\n","        if cache_prefix is not None:\n","            cache_id = f\"{cache_prefix}{start_idx}-{end_idx}\"\n","            if cache_id in gpu_cache:\n","                return gpu_cache[cache_id]\n","            if cache_id in ram_cache:\n","                return self.span_dict_to_device(ram_cache[cache_id], \"cuda\")\n","\n","        span_representations_dict = self.extract_embeddings(tokenized_dataset, start_idx, end_idx, pad=True)\n","        span1_torch = torch.stack(span_representations_dict[\"span1\"]).float().to(self.MLP_device)  # (batch_size, #layers, max_span_len, embd_dim)\n","        span1_attention_mask_torch = torch.stack(span_representations_dict[\"span1_attention_mask\"])\n","        one_hot_labels_torch = torch.tensor(np.array(span_representations_dict[\"one_hot_label\"]))\n","        if self.num_of_spans == 2:\n","            span2_torch = torch.stack(span_representations_dict[\"span2\"]).float().to(self.MLP_device)\n","            span2_attention_mask_torch = torch.stack(span_representations_dict[\"span1_attention_mask\"])\n","            spans_torch_dict = {\"span1\": span1_torch, \n","                                \"span2\": span2_torch, \n","                                \"span1_attention_mask\": span1_attention_mask_torch, \n","                                \"span2_attention_mask\": span2_attention_mask_torch, \n","                                \"one_hot_labels\": one_hot_labels_torch}\n","        elif self.num_of_spans == 1:\n","            spans_torch_dict = {\"span1\": span1_torch, \n","                                \"span1_attention_mask\": span1_attention_mask_torch, \n","                                \"one_hot_labels\": one_hot_labels_torch}\n","\n","        if cache_prefix is not None:\n","            if len(gpu_cache) < GPU_CACHE_LEN:\n","                gpu_cache[cache_id] = spans_torch_dict\n","                print(cache_id, end=\"|\")\n","            elif len(ram_cache) < RAM_CACHE_LEN:\n","                ram_cache[cache_id] = self.span_dict_to_device(spans_torch_dict, \"cpu\")\n","                print(cache_id, end=\",\")\n","        return spans_torch_dict\n","\n","    def get_language_model_properties(self):\n","        span_representations_dict = self.extract_embeddings(self.dataset_handler.tokenized_dataset[\"train\"], 0, 3, pad=True)\n","        for i in span_representations_dict[\"span1\"]:\n","            print(i.shape)\n","        span1_torch = span_representations_dict[\"span1\"]\n","        num_layers = span1_torch[0].shape[0]\n","        span_len = span1_torch[0].shape[1]\n","        embedding_dim = span1_torch[0].shape[2]\n","        return num_layers, span_len, embedding_dim, len(self.dataset_handler.labels_list)\n","\n","    def pad_span(self, span_repr, max_len):\n","        \"\"\" pad spans in embeddings to max_len \n","        input:\n","            span_representation: df with shape (#layers, span_len, embedding_dim)\n","        returns:\n","            padded_spans: np with shape (batch_len, num_layers, max_len, embedding_dim)\n","            attention_mask: np with shape (max_len), values = 1: data, 0: padding\n","        \"\"\"\n","        shape = span_repr.shape\n","        num_layers = shape[0]\n","        span_original_len = shape[1]\n","        embedding_dim = shape[2]\n","        attention_mask = torch.ones(max_len, dtype=torch.int8, device=self.device)\n","        attention_mask[span_original_len:] = 0\n","\n","        padded_span_repr = torch.cat((span_repr, torch.zeros((num_layers, max_len - span_original_len, embedding_dim), device=self.device)), axis=1)\n","        return padded_span_repr, attention_mask\n","\n","    def init_span_dict(self, num_of_spans, pad):\n","        if num_of_spans == 2:\n","            span_repr = {\"span1\": [], \"span2\": [], \"label\": [], \"one_hot_label\": []}\n","        else:\n","            span_repr = {\"span1\": [], \"label\": [], \"one_hot_label\": []}\n","        \n","        if pad:\n","            span_repr[\"span1_attention_mask\"] = []\n","            span_repr[\"span2_attention_mask\"] = []\n","        return span_repr\n","\n","    def extract_glove(self, tokenized_dataset, idx, span_start, span_end):\n","        text = tokenized_dataset[idx][\"text\"]\n","        embedding_dim = word_embedding.word_vectors.shape[-1]\n","        span_len = span_end - span_start\n","        hidden_states = torch.zeros(1, span_len, embedding_dim, device=self.device)  #(layers, span_len, embedding_dim)\n","        for i in range(span_len):\n","            word = text[span_start + i]\n","            if word in word_embedding.dictionary:\n","                hidden_states[0, i, :] = torch.tensor(word_embedding.word_vectors[word_embedding.dictionary[word]], device=self.device)\n","            else:\n","                pass\n","        return hidden_states\n","\n","    def extract_elmo(self, tokenized_dataset, idx, span_start, span_end):\n","        text = \" \".join(tokenized_dataset[idx][\"text\"])\n","        hidden_states = elmo.get_elmo_embedding(text)\n","        return hidden_states[:, span_start:span_end, :]\n","\n","\n","    def extract_batch(self, tokenized_dataset, idx, unique_batch_size=32):\n","        # self.vprint(\"e1\")\n","        dataset_len = len(tokenized_dataset)\n","        unique_texts_in_batch = []\n","        i = idx\n","        while len(unique_texts_in_batch) < unique_batch_size and i < dataset_len:\n","            text = tokenized_dataset[i][\"text\"]\n","            if not text in unique_texts_in_batch:\n","                unique_texts_in_batch.append(text)\n","            i += 1\n","        tokenizer.padding_side = 'right'  # Important: lef will change the span indices\n","        tokenized_batch = tokenizer(unique_texts_in_batch, padding=True, return_tensors=\"pt\").to(self.device)\n","        with torch.no_grad():\n","            if SEQ2SEQ_MODEL:\n","                outputs = self.language_model(input_ids=tokenized_batch.input_ids, decoder_input_ids=tokenized_batch.input_ids, output_hidden_states=True)\n","            else:\n","                outputs = self.language_model(**tokenized_batch)\n","        if SEQ2SEQ_MODEL:\n","            encoder_hidden_states = torch.stack([val.detach() for val in outputs.encoder_hidden_states])\n","            decoder_hidden_states = torch.stack([val.detach() for val in outputs.decoder_hidden_states])\n","            current_hidden_states = torch.cat((encoder_hidden_states, decoder_hidden_states), dim=0)  # concat from layers\n","        else:\n","            current_hidden_states = torch.stack([val.detach() for val in outputs.hidden_states])\n","        \n","        extracted_batch_embeddings = {}\n","        for i, unique_text in enumerate(unique_texts_in_batch):\n","            hashable_input = repr(unique_text)\n","            if not hasattr(self, 'up_to_layer') or self.up_to_layer == -1:\n","                extracted_batch_embeddings[hashable_input] = current_hidden_states[:, i, :, :]\n","            else:\n","                extracted_batch_embeddings[hashable_input] = current_hidden_states[:self.up_to_layer+1, i, :, :]\n","        self.vprint(\"e2\")\n","        return extracted_batch_embeddings\n","    \n","    def pad_sequence(list_of_torch, pad_len, pad_value=0):\n","        shape = list_of_torch[0].shape\n","        num_layers = shape[0]\n","        span_original_len = shape[1]\n","        embedding_dim = shape[2]\n","        output = torch.zeros()\n","\n","    def extract_embeddings(self, tokenized_dataset, start_idx, end_idx, pad=True):\n","        \"\"\" Extract raw embeddings for [start_idx, end_idx) of tokenized_dataset from language_model \n","            \n","        Returns:\n","            extract_embeddings: DataFrame with cols (span1, span2?, label) and span shape is (range_len, (#layers, span_len, embedding_dim))\n","        \"\"\"\n","        num_of_spans = self.dataset_handler.dataset_info.num_of_spans\n","        \n","        if num_of_spans == 2:\n","            max_span_len_in_batch = max(max(tokenized_dataset[start_idx:end_idx][\"span1_len\"]), max(tokenized_dataset[start_idx:end_idx][\"span2_len\"]))\n","        elif num_of_spans == 1:\n","            max_span_len_in_batch = max(tokenized_dataset[start_idx:end_idx][\"span1_len\"])\n","        \n","\n","        span_repr = self.init_span_dict(num_of_spans, pad)\n","        self.vprint(\"f1\")\n","        for i in range(start_idx, end_idx):\n","            row = tokenized_dataset[i]\n","            if \"glove\" in model_checkpoint:\n","                span1_hidden_states = self.extract_glove(tokenized_dataset, i, row[\"span1\"][0], row[\"span1\"][1])\n","            elif \"elmo\" in model_checkpoint:\n","                span1_hidden_states = self.extract_elmo(tokenized_dataset, i, row[\"span1\"][0], row[\"span1\"][1])\n","                self.vprint(\"f2\")\n","            else:\n","                hashable_input = repr(tokenized_dataset[i][\"text\"])\n","                \n","                if hashable_input in self.cached_embeddings:\n","                    self.current_hidden_states = self.cached_embeddings[hashable_input]\n","                else:\n","                    if hashable_input not in self.extracted_batch_embeddings:\n","                        self.extracted_batch_embeddings = self.extract_batch(tokenized_dataset, i)\n","                    self.current_hidden_states = self.extracted_batch_embeddings[hashable_input]\n","\n","                span1_hidden_states = self.current_hidden_states[:, row[\"span1\"][0]:row[\"span1\"][1], :]  # (#layer, span_len, embd_dim)\n","            \n","            if pad:\n","                s1, a1 = self.pad_span(span1_hidden_states, max_span_len_in_batch)\n","                span_repr[\"span1\"].append(s1)\n","                span_repr[\"span1_attention_mask\"].append(a1)\n","            else:\n","                span_repr[\"span1\"].append(span1_hidden_states)\n","\n","            if num_of_spans == 2:\n","                if \"glove\" in model_checkpoint:\n","                    span2_hidden_states = self.extract_glove(tokenized_dataset, i, row[\"span2\"][0], row[\"span2\"][1])\n","                elif \"elmo\" in model_checkpoint:\n","                    span2_hidden_states = self.extract_elmo(tokenized_dataset, i, row[\"span2\"][0], row[\"span2\"][1])\n","                    self.vprint(\"f3\")\n","                else:\n","                    span2_hidden_states = self.current_hidden_states[:, row[\"span2\"][0]:row[\"span2\"][1], :]\n","                if pad:\n","                    s2, a2 = self.pad_span(span2_hidden_states, max_span_len_in_batch)\n","                    span_repr[\"span2\"].append(s2)\n","                    span_repr[\"span2_attention_mask\"].append(a2)\n","                else:\n","                    span_repr[\"span2\"].append(span2_hidden_states)\n","            span_repr[\"one_hot_label\"].append(row[\"one_hot_label\"])\n","            span_repr[\"label\"].append(row[\"label\"])\n","        self.vprint(\"f4\")\n","        return span_repr\n","\n","    def save_history(self, history_dict, mdl=False):\n","        if mdl == True:\n","            prefix = \"mdl/mdl_jsons_\"\n","            history_dict = {\"mdl_history\": history_dict}\n","        else:\n","            prefix = \"edge_probing_results_jsons/\"\n","        file_name = prefix + model_checkpoint + \"_\" + self.dataset_handler.dataset_info.dataset_name + \"_\" + str(SEED)\n","        history_dict[\"Model\"] = model_checkpoint,\n","        history_dict[\"Batch Size\"] = BATCH_SIZE,\n","        history_dict[\"Learning Rate\"] = LEARNING_RATE,\n","        history_dict[\"seed\"] = SEED\n","        if hasattr(self, 'edge_probe_model'):\n","            history_dict[\"probe_summary\"] = self.edge_probe_model.summary(do_print=False)\n","        elif hasattr(self, 'edge_probe_models'):\n","            history_dict[\"probe_summary\"] = self.edge_probe_models[0].summary(do_print=False)\n","        else:\n","            print(\"No Probe Found to Summarize!\")\n","        history_dict[\"dataset_name\"] = self.dataset_handler.dataset_info.dataset_name\n","        history_dict[\"dataset_statistics\"] = str(self.dataset_handler.dataset)\n","\n","        from pathlib import Path\n","        Path(file_name).mkdir(parents=True, exist_ok=True)\n","        with open(f\"{file_name}.json\", \"w\") as json_file:\n","            json.dump(history_dict, json_file, indent=4)\n","\n","\"\"\"# Edge Probe Trainer\"\"\"\n","\n","class Edge_probe_trainer(Trainer):\n","    # Public:\n","    def __init__(self, language_model, dataset_handler: Dataset_handler, \n","                 verbose=True, device='cuda', edge_probe_model_checkpoint=None,\n","                 pool_method=\"attn\", start_eval = False, \n","                 history_checkpoint=None, up_to_layer=-1, normalize_layers=False,\n","                 patience=5):\n","        self.dataset_handler = dataset_handler\n","        self.num_of_spans = self.dataset_handler.dataset_info.num_of_spans\n","        self.up_to_layer = up_to_layer\n","        self.language_model = language_model\n","        self.language_model.config.output_hidden_states = True\n","        self.device = device\n","        self.verbose = verbose\n","        self.start_eval = start_eval\n","        def vprint(text):\n","            if verbose:\n","                print(datetime.datetime.now().time(), text)\n","        self.vprint = vprint\n","\n","        self.current_hidden_states = None\n","        self.last_input_ids = None\n","        self.extracted_batch_embeddings = {}\n","\n","        self.cached_embeddings = {}\n","\n","        self.vprint(\"Moving to device\")\n","        for param in self.language_model.parameters():\n","            param.requires_grad = False\n","        self.language_model.eval()\n","        self.language_model.to(self.device)\n","        num_layers, input_span_len, embedding_dim, num_classes = self.get_language_model_properties()\n","        self.MLP_device = self.device\n","        self.patience = patience\n","        self.counter_4_early_stopping = 0\n","        if edge_probe_model_checkpoint == None:\n","            print(\"Creating New EPM\")\n","            self.edge_probe_model = Edge_probe_model(\n","                num_of_spans = self.num_of_spans,\n","                num_layers = num_layers,\n","                input_span_len = input_span_len,\n","                embedding_dim = embedding_dim, \n","                num_classes = num_classes,\n","                device = self.MLP_device,\n","                pool_method = pool_method,\n","                normalize_layers = normalize_layers\n","            )\n","        else:\n","            print(\"Starting From a Pretrained EPM\")\n","            self.edge_probe_model = edge_probe_model_checkpoint\n","        \n","\n","        if history_checkpoint is None:\n","            self.history = {\"loss\": {\"train\": [], \"dev\": [], \"test\": []}, \n","                            \"metrics\": \n","                            {\n","                                \"micro_f1\": {\"dev\": [], \"test\": []},\n","                                \"macro_f1\": {\"dev\": [], \"test\": []},\n","                                \"accuracy\": {\"dev\": [], \"test\": []},\n","                                \"report\": {\"dev\": [], \"test\": []},\n","                                \"f1\": {\"dev\": [], \"test\": []}\n","                            },\n","\n","                            \"layers_weights\": [],\n","                            }\n","            print(\"Creating New History\")\n","        else:\n","            print(\"Using History Checkpoint\")\n","            self.history = history_checkpoint\n","    \n","    def train(self, batch_size, epochs=3):\n","        tokenized_dataset = self.dataset_handler.tokenized_dataset[\"train\"]\n","        tokenized_dataset_dev = self.dataset_handler.tokenized_dataset[\"dev\"]\n","        tokenized_dataset_test = self.dataset_handler.tokenized_dataset[\"test\"]\n","\n","        self.edge_probe_model.to(self.MLP_device)\n","        dataset_len = len(tokenized_dataset)\n","        dev_dataset_len = len(tokenized_dataset_dev)\n","        test_dataset_len = len(tokenized_dataset_test)\n","        print(f\"Train on {dataset_len} samples, validate on {dev_dataset_len} samples, test on {test_dataset_len} samples\")\n","        if self.start_eval:\n","            self.update_history(epoch = 0)\n","\n","        step_counter = 0\n","        for epoch in range(epochs):\n","            running_loss = 0.0\n","            steps = 0\n","            print(\"----------------\\n\")\n","            self.edge_probe_model.train()\n","            for i in tqdm(range(0, dataset_len, batch_size), desc=f\"[Epoch {epoch + 1}/{epochs}]\"):\n","                \n","                self.vprint(\"Start\")\n","                step = batch_size\n","                if i + batch_size > dataset_len:\n","                    step = dataset_len - i\n","                \n","                self.vprint(\"Extracting\")\n","                spans_torch_dict = self.prepare_batch_data(tokenized_dataset, i, i + step, pad=True, cache_prefix=\"t\")\n","                labels = spans_torch_dict[\"one_hot_labels\"]\n","                # zero the parameter gradients\n","                self.edge_probe_model.optimizer.zero_grad()\n","    \n","                # forward + backward + optimize\n","                self.vprint(\"Forward MLP\")\n","                outputs = self.edge_probe_model(spans_torch_dict)\n","                self.vprint(\"Loss\")\n","                loss = self.edge_probe_model.training_criterion(outputs.to(self.device), labels.float().to(self.device))\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(self.edge_probe_model.parameters(), 5.0)\n","                self.edge_probe_model.optimizer.step()\n","    \n","                running_loss += loss.item()\n","                steps += 1\n","                self.vprint(\"Done\")\n","            self.update_history(epoch + 1, train_loss = running_loss / steps)\n","            self.save_history(self.history)\n","            if self.check_early_stop():\n","                break;\n","\n","\n","    def check_early_stop(self):\n","        if len(self.history['loss']['dev']) > 1:\n","            if self.history['loss']['dev'][-1] > self.history['loss']['dev'][-2]:\n","                self.counter_4_early_stopping += 1\n","            if self.history['loss']['dev'][-1] < self.history['loss']['dev'][-2]:\n","                self.counter_4_early_stopping = 0\n","        \n","        print(f\"Early Stopping Counter: {self.counter_4_early_stopping}\")\n","\n","        if self.counter_4_early_stopping >= self.patience:\n","            return True\n","        \n","        return False\n","\n","###added predictions by Polina\n","    def predict(self, tokenized_dataset, batch_size=16, desc=\"\"):\n","        self.edge_probe_model.eval()\n","        with torch.no_grad():\n","            running_loss = 0\n","            dataset_len = len(tokenized_dataset[\"text\"])\n","            steps = 0\n","            preds = None\n","            for i in tqdm(range(0, dataset_len, batch_size), desc=desc):\n","                step = batch_size\n","                if i + batch_size > dataset_len:\n","                    step = dataset_len - i\n","                \n","                #if desc == \"Test Loss\":\n","                spans_torch_dict = self.prepare_batch_data(tokenized_dataset, i, i + step, pad=True, cache_prefix=\"test\")\n","                #else:\n","                #    spans_torch_dict = self.prepare_batch_data(tokenized_dataset, i, i + step, pad=True)\n","                labels = spans_torch_dict[\"one_hot_labels\"]\n","                # forward\n","                outputs = self.edge_probe_model(spans_torch_dict)\n","                \n","                preds = outputs if i == 0 else torch.cat((preds, outputs), 0)\n","                loss = self.edge_probe_model.training_criterion(outputs.to(self.device), labels.float().to(self.device))\n","                running_loss += loss.item()\n","                steps += 1\n","\n","        #preds = preds.cpu().argmax(-1)\n","        return preds\n","###\n","\n","    def calc_loss(self, tokenized_dataset, batch_size=16, print_metrics=False, just_micro=False, desc=\"\"):\n","        self.edge_probe_model.eval()\n","        with torch.no_grad():\n","            running_loss = 0\n","            dataset_len = len(tokenized_dataset[\"text\"])\n","            steps = 0\n","            preds = None\n","            for i in tqdm(range(0, dataset_len, batch_size), desc=desc):\n","                step = batch_size\n","                if i + batch_size > dataset_len:\n","                    step = dataset_len - i\n","                \n","                if desc == \"Test Loss\":\n","                    spans_torch_dict = self.prepare_batch_data(tokenized_dataset, i, i + step, pad=True, cache_prefix=\"test\")\n","                else:\n","                    spans_torch_dict = self.prepare_batch_data(tokenized_dataset, i, i + step, pad=True)\n","                labels = spans_torch_dict[\"one_hot_labels\"]\n","                # forward\n","                outputs = self.edge_probe_model(spans_torch_dict)\n","                \n","                preds = outputs if i == 0 else torch.cat((preds, outputs), 0)\n","                loss = self.edge_probe_model.training_criterion(outputs.to(self.device), labels.float().to(self.device))\n","                running_loss += loss.item()\n","                steps += 1\n","\n","        preds = preds.cpu().argmax(-1)\n","        y_true = np.array(tokenized_dataset[\"one_hot_label\"]).argmax(-1)\n","        labels_list = self.dataset_handler.labels_list\n","        if self.dataset_handler.dataset_info.dataset_name == \"semeval\":\n","            other_idx = labels_list.index(\"Other\")\n","            semeval_labels = [i for i in range(len(labels_list))]\n","            semeval_labels.remove(other_idx)\n","            print(f\"Other -> {other_idx} / {semeval_labels}\")\n","            micro_f1 = f1_score(y_true, preds, average='micro', labels=semeval_labels)\n","            macro_f1 = f1_score(y_true, preds, average='macro', labels=semeval_labels)\n","        else:\n","            micro_f1 = f1_score(y_true, preds, average='micro')\n","            macro_f1 = f1_score(y_true, preds, average='macro')\n","        \n","        accuracy = sklearn.metrics.accuracy_score(y_true, preds)\n","        \n","        \n","        report = classification_report(y_true, preds, target_names=labels_list, labels=range(len(labels_list)))\n","        report_dict = classification_report(y_true, preds, target_names=labels_list, labels=range(len(labels_list)), output_dict=True)\n","        if print_metrics:\n","            if not just_micro and desc == \"Test Loss\":\n","                print(report)\n","            print(\"MICRO F1:\", micro_f1)\n","        return running_loss / steps, micro_f1, macro_f1, accuracy, report, report_dict\n","\n","    # Private:\n","    def update_history(self, epoch, train_loss = None):\n","        if train_loss is None:\n","            train_loss, train_f1 = self.calc_loss(self.dataset_handler.tokenized_dataset[\"train\"], print_metrics=True, desc=\"Train Loss\")\n","        dev_loss, dev_f1, dev_macro_f1, dev_accuracy, dev_report, dev_report_dict = self.calc_loss(self.dataset_handler.tokenized_dataset[\"dev\"], print_metrics=True, desc=\"Dev Loss\")\n","        test_loss, test_f1, test_macro_f1, test_accuracy, test_report, test_report_dict = self.calc_loss(self.dataset_handler.tokenized_dataset[\"test\"], print_metrics=True, desc=\"Test Loss\")\n","        self.history[\"loss\"][\"train\"].append(train_loss)\n","        self.history[\"loss\"][\"dev\"].append(dev_loss)\n","        self.history[\"loss\"][\"test\"].append(test_loss)\n","\n","        self.history[\"metrics\"][\"micro_f1\"][\"dev\"].append(dev_f1)\n","        self.history[\"metrics\"][\"accuracy\"][\"dev\"].append(dev_accuracy)\n","        #print(dev_report_dict.keys())\n","        literal_key = 'Non-metaphor'\n","        non_literal_key = 'Metaphor'\n","        dev_f1_class_literal = dev_report_dict[literal_key]['f1-score']\n","        dev_f1_class_non_literal = dev_report_dict[non_literal_key]['f1-score']\n","        self.history[\"metrics\"][\"f1\"][\"dev\"].append((dev_f1_class_literal, dev_f1_class_non_literal))\n","\n","        self.history[\"metrics\"][\"micro_f1\"][\"test\"].append(test_f1)\n","        self.history[\"metrics\"][\"accuracy\"][\"test\"].append(test_accuracy)\n","        self.history[\"metrics\"][\"report\"][\"test\"].append(test_report)\n","        test_f1_class_literal = test_report_dict[literal_key]['f1-score']\n","        test_f1_class_non_literal = test_report_dict[non_literal_key]['f1-score']\n","        self.history[\"metrics\"][\"f1\"][\"test\"].append((test_f1_class_literal, test_f1_class_non_literal))\n","\n","\n","        self.history[\"layers_weights\"].append(torch.nn.functional.softmax(self.edge_probe_model.weighing_params).tolist())\n","        print('[%d] loss: %.4f, val_loss: %.4f, test_loss: %.4f' % (epoch, self.history[\"loss\"][\"train\"][-1], self.history[\"loss\"][\"dev\"][-1], self.history[\"loss\"][\"test\"][-1]))\n","\n","    def draw_weights(self, epoch=0):\n","        if(epoch % 1 == 0):\n","            w = torch.nn.functional.softmax(self.edge_probe_model.weighing_params).cpu().detach().numpy()\n","            print(w)\n","            plt.bar(np.arange(len(w), dtype=int), w)\n","            plt.ylabel('Weight')\n","            plt.xlabel('Layer');\n","            plt.show()\n","\n","            wsoft = nn.functional.softmax(self.edge_probe_model.weighing_params)\n","            print(\"CG\", sum(idx*val for idx, val in enumerate(wsoft)))\n","\n","            print(\"Loss History\")\n","            loss_history = self.history[\"loss\"]\n","            x = range(len(loss_history[\"train\"]))\n","            plt.plot(x, loss_history[\"train\"])\n","            plt.plot(x, loss_history[\"dev\"])\n","            plt.plot(x, loss_history[\"test\"])\n","            plt.legend(['Train', 'Dev', 'Test'], loc='lower left')\n","            plt.show()\n","\n","            print(\"Micro f1 History\")\n","            f1_history = self.history[\"metrics\"][\"micro_f1\"]\n","            x = range(len(f1_history[\"dev\"]))\n","            plt.plot(x, f1_history[\"dev\"])\n","            plt.plot(x, f1_history[\"test\"])\n","            plt.legend(['Dev', 'Test'], loc='upper left')\n","            plt.show()\n","\n","    def analyze_attention(self, dataset_part=\"train\", row_idx=0, new_text = None):\n","        if new_text is not None:\n","            new_dataset_info = Dataset_info(\"manual\", num_of_spans=1, manual_text=new_text)\n","            new_dataset_handler = Dataset_handler(new_dataset_info);\n","            dataset_part = \"test\"\n","            row_idx=0\n","            tokenized_dataset = new_dataset_handler.tokenized_dataset[dataset_part]\n","        else:\n","            tokenized_dataset = self.dataset_handler.tokenized_dataset[dataset_part]\n","        \n","        self.edge_probe_model.eval()\n","        with torch.no_grad():\n","            spans_torch_dict = self.prepare_batch_data(tokenized_dataset, row_idx, row_idx + 1, pad=True)\n","            labels = spans_torch_dict[\"one_hot_labels\"]\n","            # forward\n","            outputs = self.edge_probe_model(spans_torch_dict)\n","        preds = outputs\n","        loss = self.edge_probe_model.training_criterion(outputs.to(self.device), labels.float().to(self.device))\n","        running_loss = loss.item()\n","        print(preds[0:9])\n","        preds = preds.cpu().argmax(-1)\n","        y_true = np.array(tokenized_dataset[\"one_hot_label\"]).argmax(-1)\n","        if \"glove\" in model_checkpoint:\n","            text = tokenized_dataset[row_idx][\"text\"]\n","        else:\n","            start = tokenized_dataset[row_idx][\"span1\"][0]\n","            end = tokenized_dataset[row_idx][\"span1\"][1]\n","            text = tokenizer.convert_ids_to_tokens(tokenized_dataset[row_idx][\"input_ids\"][start:end])\n","        return text, self.edge_probe_model.span1_pooling_net.last_attention_wts, preds, y_true[row_idx]"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["fcd6061de9df48cdb9f4bde841916a35","384c652f7f4f4055964ac4fca07b9c20","1e9239ec7b0948228fdc3b8a775f3bf0","74d25432ddc0409aac4c4de671cfd540","68d45123c6e440f584f41aecce7cf6be","9b7ce3d3be2744419e703094b6c42e2e","48deee40eacf4eb990e56316e87fc702","3ea2e6fb75834bf7a9a36f209c6294b5","e70d5eccb33e4684b97a001a080dd35c","6eec74c1b7514b969e8d477b168cd43b","45f5e2c547c74708a07717aa18971af1","90300eba822f49d8b8e82197b8a316aa","e9f350b65f49485fb9d8142cf1ed6cfa","fd14308d806b48cebc284c9285f0fa4c","c7a120468be64a08850d47d384e8f314","bf7058fd818a4d00affd003b45d14559","3891032aa9244a9bbff9fcbc005ca367","9be9e4fcb12847f0b19fac944aba0ac7","7f20a1fd78784e538548771b3b59be5d","48e2a256774d472886d4a25ac253e0aa","b633cd1e6eb54de8b22093fae5d7a380","332438ac3025409eb53d5fadc7722d24","ffc195c1284f40888fda6c42b4597555","ad3d1e4b3ef54387ba444aa95ce70a21","49080faf1055459aaa5027c1cf9e03f3","2cc52807121a4c2ebf3735fd04c66513","d43509df337c471cbd16a2c2d6de3d8d","2fe930b6df044cc8b281222fabaea59f","7309952c22af4e66b9c9e03a7e628133","52b8fefcf3b0490980c9e51618f164da","ff6006dcaa334fbebed53372c59d3229","98bc9e320e4d4cbd877d8016dfd03818","6051a81198c74f56910fc1968d9d9837","c6b89528886648dba573734d554c5871","d5acbdcf9bb2403199125797db7c64f1","d6c9a176ba8d48f788f42fffdc4a1e0d","34bff980a41048e9a2751ea8d226a612","c5a6691454524e01b14b996daeabb5b1","22e0a9a4ebeb42b386c7ff7e3ce8611a","fe8ed4e36692440bbfeb990768130dbf","0975b2acaa0a4147a1e219a36ba67871","057af433426047bd8d728734b5fe2e15","6e0755ff5e1d4e978a4dd8b29a3521ec","7456173f8fc64e7abe15e2ec51af9592","ee299e976c7f4058800d6144a4ed658e","ad45c3f4a17d4a0e86b42368e8f22f3d","f2fe4b7b766d44e48808235da9156917","9d0ddff4c267466380e6326dea9881a7","1b16b46123ea4d91a0e2be9bced62e54","ef59ad97fa0c499e825276bff0c99294","bdbd3e6e21d040418f82b5ef89a96db2","4ac061cbd43d448b83bbb0ad1fc0a517","3bbeac6ada0a43f1b9629edf7df16686","c1e7c08eb54d489fbaec4b79bab68a8c","2d58502ce27a4059956ca3b6cd7798fb","97c7d8b523804de3a0106c0cbd62a808","030d7277a713416194ebe7d971c63117","09cc159bfd3c45f4b8bcc559066beb46","4289a42773e54827a33868ac81254fea","98c05390cc51499bb952d574ec904e2a","b8f92dceeb53495180c88a2d6fcf13c5","b581cc5ab9d94444b41604672a3b29b5","e925f009ba4f4bd09c31e95c5075124d","1f8d1f82bef446af9e0ad6b2a17e2fc6","a91945574af64f458628124e865308fd","7ebb1e64ca644e49b6e6d747e7d15491","992b8de9d0724bbab13bd18bfd1ef001","f4673aedc250428d8bf7153c32cc0933","7bc0254167434b09b6fe92b448e02b99","93d5a48921134d80898e4c76030495c7","981117f4d7c643e287c7b78e71a316de","6392aeef209e4b8f81a91cb06bc0aae3","4442247e409d45a3819e933c16124a45","08490dda3d06467bafccf7d70d8ae7d7","712091ea7ef64f959806b7a0a6224d6b","527cf13e8bd14f6b9862ee9d57288d04","2f1c29403740460da037bc84af72b13d","e6be5a5b591b4844945c6b2114587fb9","c7d32a5971b34c6b8fb539ca22d3d63e","5bb53eb6cf1745ecb009a6c14163a925","b9d4072cf93e429bb6db3f520b918d73","6a1610f1f46f43e8bb879b9b6cc5c0ad","fbddd5640bf44b629c8422484b8a19c9","bfde49eb05304e01ae59786280cee301","3d22fdc97d9b4d68a232f4bc857493e9","00e14428b5ad4857ba05b8f55d28186c","6e953ef48dc344d1b1c448cda564e6c1","fe01785b2af6416c94b33a4a60d167a5","bdacf89318d64fcca79c5b70dc5fbd31","8952a884e48445179b8de69e909a2792","6ba799230c744276a011bf9a296dd0e8","6ce9d8ea6dc44ff0b272004228feece2","7f6002a2a99e46598b8c47b739e5518d","d4513a5fcde9460c93d0a653e7d9599c","d9354fd57c3242a8bb221098219fbeea","8fd68f77ab15410096474fc49dd27389","45150cda34574b55a04937701109378a","bc15146099dd47a2a7662557e87a3a58","c663b61e9be54a048632d2ac4b0c5b21"]},"id":"UNjlhm8YpppG","executionInfo":{"status":"ok","timestamp":1655201311236,"user_tz":-180,"elapsed":164799,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"}},"outputId":"29f690d6-1925-4515-9b7e-6520feadd8a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([13, 1, 768])\n","torch.Size([13, 1, 768])\n","torch.Size([13, 1, 768])\n","Creating New EPM\n","Creating New History\n","Model: DeepPavlov/rubert-base-cased-conversational\n","Dataset: lcc+yulia_lcc+yulia_rusidio\n","Batch Size: 32\n","Edge_probe_model(\n","  (proj1): Linear(in_features=768, out_features=256, bias=True)\n","  (span1_pooling_net): AttnSpanRepr(\n","    (attention_params): Linear(in_features=256, out_features=1, bias=True)\n","  )\n","  (training_criterion): BCELoss()\n","  (label_net): Sequential(\n","    (0): Linear(in_features=256, out_features=256, bias=True)\n","    (1): Tanh()\n","    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (3): Dropout(p=0.3, inplace=False)\n","    (4): Linear(in_features=256, out_features=2, bias=True)\n","    (5): Sigmoid()\n","  )\n",")\n"," Total Parameters:     263952\n"," Trainable Parameters: 263952\n"," Pool Method: attn\n"," Projection: True, 256\n"," normalize_layers: True\n","Train on 17387 samples, validate on 2355 samples, test on 2643 samples\n","----------------\n","\n"]},{"output_type":"display_data","data":{"text/plain":["[Epoch 1/35]:   0%|          | 0/544 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcd6061de9df48cdb9f4bde841916a35"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["t0-32|t32-64|t64-96|t96-128|t128-160|t160-192|t192-224|t224-256|t256-288|t288-320|t320-352|t352-384|t384-416|t416-448|t448-480|t480-512|t512-544|t544-576|t576-608|t608-640|t640-672|t672-704|t704-736|t736-768|t768-800|t800-832|t832-864|t864-896|t896-928|t928-960|t960-992|t992-1024|t1024-1056|t1056-1088|t1088-1120|t1120-1152|t1152-1184|t1184-1216|t1216-1248|t1248-1280|t1280-1312|t1312-1344|t1344-1376|t1376-1408|t1408-1440|t1440-1472|t1472-1504|t1504-1536|t1536-1568|t1568-1600|t1600-1632|t1632-1664|t1664-1696|t1696-1728|t1728-1760|t1760-1792|t1792-1824|t1824-1856|t1856-1888|t1888-1920|t1920-1952|t1952-1984|t1984-2016|t2016-2048|t2048-2080|t2080-2112|t2112-2144|t2144-2176|t2176-2208|t2208-2240|t2240-2272|t2272-2304|t2304-2336|t2336-2368|t2368-2400|t2400-2432|t2432-2464|t2464-2496|t2496-2528|t2528-2560|t2560-2592|t2592-2624|t2624-2656|t2656-2688|t2688-2720|t2720-2752|t2752-2784|t2784-2816|t2816-2848|t2848-2880|t2880-2912|t2912-2944|t2944-2976|t2976-3008|t3008-3040|t3040-3072|t3072-3104|t3104-3136|t3136-3168|t3168-3200|t3200-3232|t3232-3264|t3264-3296|t3296-3328|t3328-3360|t3360-3392|t3392-3424|t3424-3456|t3456-3488|t3488-3520|t3520-3552|t3552-3584|t3584-3616|t3616-3648|t3648-3680|t3680-3712|t3712-3744|t3744-3776|t3776-3808|t3808-3840|t3840-3872|t3872-3904|t3904-3936|t3936-3968|t3968-4000|t4000-4032|t4032-4064|t4064-4096|t4096-4128|t4128-4160|t4160-4192|t4192-4224|t4224-4256|t4256-4288|t4288-4320|t4320-4352|t4352-4384|t4384-4416|t4416-4448|t4448-4480|t4480-4512|t4512-4544|t4544-4576|t4576-4608|t4608-4640|t4640-4672|t4672-4704|t4704-4736|t4736-4768|t4768-4800|t4800-4832|t4832-4864|t4864-4896|t4896-4928|t4928-4960|t4960-4992|t4992-5024|t5024-5056|t5056-5088|t5088-5120|t5120-5152|t5152-5184|t5184-5216|t5216-5248|t5248-5280|t5280-5312|t5312-5344|t5344-5376|t5376-5408|t5408-5440|t5440-5472|t5472-5504|t5504-5536|t5536-5568|t5568-5600|t5600-5632|t5632-5664|t5664-5696|t5696-5728|t5728-5760|t5760-5792|t5792-5824|t5824-5856|t5856-5888|t5888-5920|t5920-5952|t5952-5984|t5984-6016|t6016-6048|t6048-6080|t6080-6112|t6112-6144|t6144-6176|t6176-6208|t6208-6240|t6240-6272|t6272-6304|t6304-6336|t6336-6368|t6368-6400|t6400-6432|t6432-6464|t6464-6496|t6496-6528|t6528-6560|t6560-6592|t6592-6624|t6624-6656|t6656-6688|t6688-6720|t6720-6752|t6752-6784|t6784-6816|t6816-6848|t6848-6880|t6880-6912|t6912-6944|t6944-6976|t6976-7008|t7008-7040|t7040-7072|t7072-7104|t7104-7136|t7136-7168|t7168-7200|t7200-7232|t7232-7264|t7264-7296|t7296-7328|t7328-7360|t7360-7392|t7392-7424|t7424-7456|t7456-7488|t7488-7520|t7520-7552|t7552-7584|t7584-7616|t7616-7648|t7648-7680|t7680-7712|t7712-7744|t7744-7776|t7776-7808|t7808-7840|t7840-7872|t7872-7904|t7904-7936|t7936-7968|t7968-8000|t8000-8032|t8032-8064|t8064-8096|t8096-8128|t8128-8160|t8160-8192|t8192-8224|t8224-8256|t8256-8288|t8288-8320|t8320-8352|t8352-8384|t8384-8416|t8416-8448|t8448-8480|t8480-8512|t8512-8544|t8544-8576|t8576-8608|t8608-8640|t8640-8672|t8672-8704|t8704-8736|t8736-8768|t8768-8800|t8800-8832|t8832-8864|t8864-8896|t8896-8928|t8928-8960|t8960-8992|t8992-9024|t9024-9056|t9056-9088|t9088-9120|t9120-9152|t9152-9184|t9184-9216|t9216-9248|t9248-9280|t9280-9312|t9312-9344|t9344-9376|t9376-9408|t9408-9440|t9440-9472|t9472-9504|t9504-9536|t9536-9568|t9568-9600|t9600-9632|t9632-9664|t9664-9696|t9696-9728|t9728-9760|t9760-9792|t9792-9824|t9824-9856|t9856-9888|t9888-9920|t9920-9952|t9952-9984|t9984-10016|t10016-10048|t10048-10080|t10080-10112|t10112-10144|t10144-10176|t10176-10208|t10208-10240|t10240-10272|t10272-10304|t10304-10336|t10336-10368|t10368-10400|t10400-10432|t10432-10464|t10464-10496|t10496-10528|t10528-10560|t10560-10592|t10592-10624|t10624-10656|t10656-10688|t10688-10720|t10720-10752|t10752-10784|t10784-10816|t10816-10848|t10848-10880|t10880-10912|t10912-10944|t10944-10976|t10976-11008|t11008-11040|t11040-11072|t11072-11104|t11104-11136|t11136-11168|t11168-11200|t11200-11232|t11232-11264|t11264-11296|t11296-11328|t11328-11360|t11360-11392|t11392-11424|t11424-11456|t11456-11488|t11488-11520|t11520-11552|t11552-11584|t11584-11616|t11616-11648|t11648-11680|t11680-11712|t11712-11744|t11744-11776|t11776-11808|t11808-11840|t11840-11872|t11872-11904|t11904-11936|t11936-11968|t11968-12000|t12000-12032|t12032-12064|t12064-12096|t12096-12128|t12128-12160|t12160-12192|t12192-12224|t12224-12256|t12256-12288|t12288-12320|t12320-12352|t12352-12384|t12384-12416|t12416-12448|t12448-12480|t12480-12512|t12512-12544|t12544-12576|t12576-12608|t12608-12640|t12640-12672|t12672-12704|t12704-12736|t12736-12768|t12768-12800|t12800-12832|t12832-12864|t12864-12896|t12896-12928|t12928-12960|t12960-12992|t12992-13024|t13024-13056|t13056-13088|t13088-13120|t13120-13152|t13152-13184|t13184-13216|t13216-13248|t13248-13280|t13280-13312|t13312-13344|t13344-13376|t13376-13408|t13408-13440|t13440-13472|t13472-13504|t13504-13536|t13536-13568|t13568-13600|t13600-13632|t13632-13664|t13664-13696|t13696-13728|t13728-13760|t13760-13792|t13792-13824|t13824-13856|t13856-13888|t13888-13920|t13920-13952|t13952-13984|t13984-14016|t14016-14048|t14048-14080|t14080-14112|t14112-14144|t14144-14176|t14176-14208|t14208-14240|t14240-14272|t14272-14304|t14304-14336|t14336-14368|t14368-14400|t14400-14432|t14432-14464|t14464-14496|t14496-14528|t14528-14560|t14560-14592|t14592-14624|t14624-14656|t14656-14688|t14688-14720|t14720-14752|t14752-14784|t14784-14816|t14816-14848|t14848-14880|t14880-14912|t14912-14944|t14944-14976|t14976-15008|t15008-15040|t15040-15072|t15072-15104|t15104-15136|t15136-15168|t15168-15200|t15200-15232|t15232-15264|t15264-15296|t15296-15328|t15328-15360|t15360-15392|t15392-15424|t15424-15456|t15456-15488|t15488-15520|t15520-15552|t15552-15584|t15584-15616|t15616-15648|t15648-15680|t15680-15712|t15712-15744|t15744-15776|t15776-15808|t15808-15840|t15840-15872|t15872-15904|t15904-15936|t15936-15968|t15968-16000|t16000-16032|t16032-16064|t16064-16096|t16096-16128|t16128-16160|t16160-16192|t16192-16224|t16224-16256|t16256-16288|t16288-16320|t16320-16352|t16352-16384|t16384-16416|t16416-16448|t16448-16480|t16480-16512|t16512-16544|t16544-16576|t16576-16608|t16608-16640|t16640-16672|t16672-16704|t16704-16736|t16736-16768|t16768-16800|t16800-16832|t16832-16864|t16864-16896|t16896-16928|t16928-16960|t16960-16992|t16992-17024|t17024-17056|t17056-17088|t17088-17120|t17120-17152|t17152-17184|t17184-17216|t17216-17248|t17248-17280|t17280-17312|t17312-17344|t17344-17376|t17376-17387|"]},{"output_type":"display_data","data":{"text/plain":["Dev Loss:   0%|          | 0/148 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90300eba822f49d8b8e82197b8a316aa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["MICRO F1: 0.8280254777070064\n"]},{"output_type":"display_data","data":{"text/plain":["Test Loss:   0%|          | 0/166 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffc195c1284f40888fda6c42b4597555"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["test0-16|test16-32|test32-48|test48-64|test64-80|test80-96|test96-112|test112-128|test128-144|test144-160|test160-176|test176-192|test192-208|test208-224|test224-240|test240-256|test256-272|test272-288|test288-304|test304-320|test320-336|test336-352|test352-368|test368-384|test384-400|test400-416|test416-432|test432-448|test448-464|test464-480|test480-496|test496-512|test512-528|test528-544|test544-560|test560-576|test576-592|test592-608|test608-624|test624-640|test640-656|test656-672|test672-688|test688-704|test704-720|test720-736|test736-752|test752-768|test768-784|test784-800|test800-816|test816-832|test832-848|test848-864|test864-880|test880-896|test896-912,test912-928,test928-944,test944-960,test960-976,test976-992,test992-1008,test1008-1024,test1024-1040,test1040-1056,test1056-1072,test1072-1088,test1088-1104,test1104-1120,test1120-1136,test1136-1152,test1152-1168,test1168-1184,test1184-1200,test1200-1216,test1216-1232,test1232-1248,test1248-1264,test1264-1280,test1280-1296,test1296-1312,test1312-1328,test1328-1344,test1344-1360,test1360-1376,test1376-1392,test1392-1408,test1408-1424,test1424-1440,test1440-1456,test1456-1472,test1472-1488,test1488-1504,test1504-1520,test1520-1536,test1536-1552,test1552-1568,test1568-1584,test1584-1600,test1600-1616,test1616-1632,test1632-1648,test1648-1664,test1664-1680,test1680-1696,test1696-1712,test1712-1728,test1728-1744,test1744-1760,test1760-1776,test1776-1792,test1792-1808,test1808-1824,test1824-1840,test1840-1856,test1856-1872,test1872-1888,test1888-1904,test1904-1920,test1920-1936,test1936-1952,test1952-1968,test1968-1984,test1984-2000,test2000-2016,test2016-2032,test2032-2048,test2048-2064,test2064-2080,test2080-2096,test2096-2112,test2112-2128,test2128-2144,test2144-2160,test2160-2176,test2176-2192,test2192-2208,test2208-2224,test2224-2240,test2240-2256,test2256-2272,test2272-2288,test2288-2304,test2304-2320,test2320-2336,test2336-2352,test2352-2368,test2368-2384,test2384-2400,test2400-2416,test2416-2432,test2432-2448,test2448-2464,test2464-2480,test2480-2496,test2496-2512,test2512-2528,test2528-2544,test2544-2560,test2560-2576,test2576-2592,test2592-2608,test2608-2624,test2624-2640,test2640-2643,              precision    recall  f1-score   support\n","\n","Non-metaphor       0.84      0.87      0.85      2021\n","    Metaphor       0.51      0.45      0.47       622\n","\n","    accuracy                           0.77      2643\n","   macro avg       0.67      0.66      0.66      2643\n","weighted avg       0.76      0.77      0.76      2643\n","\n","MICRO F1: 0.7669315172152857\n","[1] loss: 0.4624, val_loss: 0.4078, test_loss: 0.5233\n","Early Stopping Counter: 0\n","----------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:476: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"output_type":"display_data","data":{"text/plain":["[Epoch 2/35]:   0%|          | 0/544 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6b89528886648dba573734d554c5871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dev Loss:   0%|          | 0/148 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee299e976c7f4058800d6144a4ed658e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["MICRO F1: 0.8335456475583864\n"]},{"output_type":"display_data","data":{"text/plain":["Test Loss:   0%|          | 0/166 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97c7d8b523804de3a0106c0cbd62a808"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","Non-metaphor       0.83      0.89      0.86      2021\n","    Metaphor       0.53      0.42      0.47       622\n","\n","    accuracy                           0.78      2643\n","   macro avg       0.68      0.65      0.66      2643\n","weighted avg       0.76      0.78      0.77      2643\n","\n","MICRO F1: 0.7760121074536511\n","[2] loss: 0.3215, val_loss: 0.4019, test_loss: 0.5407\n","Early Stopping Counter: 0\n","----------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:476: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"output_type":"display_data","data":{"text/plain":["[Epoch 3/35]:   0%|          | 0/544 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"992b8de9d0724bbab13bd18bfd1ef001"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dev Loss:   0%|          | 0/148 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6be5a5b591b4844945c6b2114587fb9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["MICRO F1: 0.8356687898089172\n"]},{"output_type":"display_data","data":{"text/plain":["Test Loss:   0%|          | 0/166 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdacf89318d64fcca79c5b70dc5fbd31"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","Non-metaphor       0.83      0.90      0.86      2021\n","    Metaphor       0.55      0.40      0.46       622\n","\n","    accuracy                           0.78      2643\n","   macro avg       0.69      0.65      0.66      2643\n","weighted avg       0.76      0.78      0.77      2643\n","\n","MICRO F1: 0.7824441922058267\n","[3] loss: 0.2935, val_loss: 0.4030, test_loss: 0.5500\n","Early Stopping Counter: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:476: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]}],"source":["my_edge_probe_trainer = None\n","edge_probe_model_checkpoint = None\n","history = None\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","try:\n","    edge_probe_model_checkpoint = my_edge_probe_trainer.edge_probe_model\n","except:\n","    edge_probe_model_checkpoint = None\n","my_edge_probe_trainer = Edge_probe_trainer(model,\n","                                           my_dataset_handler, \n","                                           device=DEVICE,\n","                                           pool_method=POOL_METHOD,\n","                                           edge_probe_model_checkpoint=edge_probe_model_checkpoint,\n","                                           history_checkpoint=history,\n","                                           up_to_layer = -1,\n","                                           normalize_layers=True,\n","                                           verbose=False,\n","                                           patience = 1)\n","\n","print(\"Model:\", model_checkpoint)\n","print(\"Dataset:\", my_dataset_info.dataset_name)\n","print(f\"Batch Size: {BATCH_SIZE}\")\n","a = my_edge_probe_trainer.edge_probe_model.summary(do_print=True)\n","\n","my_edge_probe_trainer.train(batch_size = BATCH_SIZE, epochs=35)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["043f921becf74ff59179894d7fe405a0","6c856369a9624541a7afbac9fd0c3ebf","a994d964e7ca43ba8715cd54ee714acc","ff17c8a21597451e9c332eed76dee005","0b2d32168e1f44c19f11d13f62e5ac7b","e5deae985c2a4286bf9e596afc0d1216","65799fbdcd2d4054944aa071eaced162","a2f4a856f309408d95d2a5751b85a13d","ed8f88eab8584064af348e6965766337","ebb440017e9a4e93aa4d6b4635c37162","2058c96efee64868a5e9d4ab8039207a"]},"executionInfo":{"elapsed":1052,"status":"ok","timestamp":1655201345849,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"aI6grYCUq2TK","outputId":"d58be2b3-20fd-4736-a8a9-503e2b6daacc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/166 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"043f921becf74ff59179894d7fe405a0"}},"metadata":{}}],"source":["preds = my_edge_probe_trainer.predict(my_dataset_handler.tokenized_dataset['test'])"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"m_oQ4uV01JDN","executionInfo":{"status":"ok","timestamp":1655201347754,"user_tz":-180,"elapsed":277,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"}}},"outputs":[],"source":["y_preds = preds.cpu().argmax(-1)\n","y_true = np.array(my_dataset_handler.tokenized_dataset['test'][\"one_hot_label\"]).argmax(-1)"]},{"cell_type":"code","source":["print(classification_report(y_true, y_preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11yRSHP45IFU","executionInfo":{"status":"ok","timestamp":1655201832556,"user_tz":-180,"elapsed":294,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"}},"outputId":"10b7bbe9-5967-426c-9237-da12f17bcfe7"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.83      0.90      0.86      2021\n","           1       0.55      0.40      0.46       622\n","\n","    accuracy                           0.78      2643\n","   macro avg       0.69      0.65      0.66      2643\n","weighted avg       0.76      0.78      0.77      2643\n","\n"]}]},{"cell_type":"code","execution_count":39,"metadata":{"id":"JFL-b5MSjs2n","executionInfo":{"status":"ok","timestamp":1655201851994,"user_tz":-180,"elapsed":702,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"}}},"outputs":[],"source":["res = pd.DataFrame(my_dataset_handler.dataset['test']).drop('__index_level_0__', axis=1)\n","res['y_true'] = y_true\n","res['prediction'] = y_preds\n","res\n","res.to_csv('./drive/MyDrive/metaphor-psycho/metaphor_annotation_fpi/res_LCC+Yulia_trained_fullinfo.csv')"]},{"cell_type":"code","source":["sum(res['prediction'])"],"metadata":{"id":"7XWnkBZ98fRR","executionInfo":{"status":"ok","timestamp":1655201853956,"user_tz":-180,"elapsed":11,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"}},"outputId":"93ce9007-c7e4-4865-bb2f-d7682207ed8a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["449"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":1279,"status":"error","timestamp":1652201438762,"user":{"displayName":"Polina Panicheva","userId":"12914424705523560436"},"user_tz":-180},"id":"ooCy6Y1B1kCK","outputId":"043ee681-ebac-4b51-e4d6-a5062a6f7339"},"outputs":[{"name":"stdout","output_type":"stream","text":["[4, 7] 6 8\n"]},{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-1195be29ef05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_dataset_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenized_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'span1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"]}],"source":["for i,y in enumerate(y_preds):\n","  if y != y_true[i]:\n","    s = my_dataset_handler.tokenized_dataset['test']['text'][i]\n","    n = my_dataset_handler.tokenized_dataset['test']['span1'][i]\n","    print(n, len(s.split()), i)\n","    print(y, y_true[i], s.split()[n], s)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2hDIP8k1q-m"},"outputs":[],"source":["data = my_dataset_handler.tokenized_dataset['test']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzgPhzZI2SjB"},"outputs":[],"source":["df.to_csv('./drive/MyDrive/metaphor-psycho/verbs_with_wfs_full.csv')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"probing_corpora.ipynb","provenance":[],"mount_file_id":"15lsi95n3I6uYHBdMIVswYLZnnEpKiXTs","authorship_tag":"ABX9TyPaS4D7xJjlN3LZvokZJLkd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bb5b2db2c2e54251ad9e368fc926984e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02df26e0650d49b7baaeb15329e18b60","IPY_MODEL_41834969de2e4d6b9b32915236bff747","IPY_MODEL_86c72db7de3b4836a6a98a7cdf707765"],"layout":"IPY_MODEL_1c9bcdfb96034b6d8965b55a760fc3b0"}},"02df26e0650d49b7baaeb15329e18b60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a24fdd35a114420f97107672033c8bb0","placeholder":"​","style":"IPY_MODEL_05e2dc03851e497c8e1e155fbf9558b9","value":"100%"}},"41834969de2e4d6b9b32915236bff747":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39c86f20913e43d988bfbde42dae8a30","max":17387,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6494d9c8ce704557b06dd7a2555aa674","value":17387}},"86c72db7de3b4836a6a98a7cdf707765":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22e9c73a281f474a8b7b48c8f26a3643","placeholder":"​","style":"IPY_MODEL_9cc41257366043e2a6612f0c902d9df0","value":" 17387/17387 [00:08&lt;00:00, 1994.00ex/s]"}},"1c9bcdfb96034b6d8965b55a760fc3b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a24fdd35a114420f97107672033c8bb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05e2dc03851e497c8e1e155fbf9558b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39c86f20913e43d988bfbde42dae8a30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6494d9c8ce704557b06dd7a2555aa674":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"22e9c73a281f474a8b7b48c8f26a3643":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cc41257366043e2a6612f0c902d9df0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63b71bd447384968a8df6a98752826aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93275ab405aa4dddb6cf3c3d948b5e9f","IPY_MODEL_4db2a3b437294b5db0ef60115d1064ca","IPY_MODEL_8b045cd7fc7543bb89c1b5b05462f766"],"layout":"IPY_MODEL_1c253effd6204546803642d69647a697"}},"93275ab405aa4dddb6cf3c3d948b5e9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a2373d8db2b4f3899a20a1b11e1c924","placeholder":"​","style":"IPY_MODEL_4bf1010f87ec400c999ff1ccd085f3a6","value":"100%"}},"4db2a3b437294b5db0ef60115d1064ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_caaed7fcadf745a38813734552013de7","max":2355,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce792c4ee4b54f5c8ab09495d22b8447","value":2355}},"8b045cd7fc7543bb89c1b5b05462f766":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0570ddb2bf4a451ba3ae3e736a8b8fc8","placeholder":"​","style":"IPY_MODEL_c8662a062cc64df8b4c796ba23662342","value":" 2355/2355 [00:01&lt;00:00, 2244.77ex/s]"}},"1c253effd6204546803642d69647a697":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a2373d8db2b4f3899a20a1b11e1c924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bf1010f87ec400c999ff1ccd085f3a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caaed7fcadf745a38813734552013de7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce792c4ee4b54f5c8ab09495d22b8447":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0570ddb2bf4a451ba3ae3e736a8b8fc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8662a062cc64df8b4c796ba23662342":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cc1c2827ac64268baac34caf2ea3e2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57b5d8eb41654397be4149e8b84acbea","IPY_MODEL_acff480ff9c94255b7c5790e7fc12724","IPY_MODEL_b257df316f76412d83406f012ae0615a"],"layout":"IPY_MODEL_6c15a77f73ff4bff84bf6ba4856a07d3"}},"57b5d8eb41654397be4149e8b84acbea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc5e0a303123432ab947b25b7eda348e","placeholder":"​","style":"IPY_MODEL_9220230c7fcc4430a7e7c5991a45d7c2","value":"100%"}},"acff480ff9c94255b7c5790e7fc12724":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c13a323dcfe4f0290722f304d399d4f","max":2643,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ae780be3f26438987410c75a0270693","value":2643}},"b257df316f76412d83406f012ae0615a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a520d4f1990a4e139119ab19782304f0","placeholder":"​","style":"IPY_MODEL_b6382bee21ee43e0b1cfc59b5d06bfc7","value":" 2643/2643 [00:00&lt;00:00, 3327.97ex/s]"}},"6c15a77f73ff4bff84bf6ba4856a07d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc5e0a303123432ab947b25b7eda348e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9220230c7fcc4430a7e7c5991a45d7c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c13a323dcfe4f0290722f304d399d4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ae780be3f26438987410c75a0270693":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a520d4f1990a4e139119ab19782304f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6382bee21ee43e0b1cfc59b5d06bfc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcd6061de9df48cdb9f4bde841916a35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_384c652f7f4f4055964ac4fca07b9c20","IPY_MODEL_1e9239ec7b0948228fdc3b8a775f3bf0","IPY_MODEL_74d25432ddc0409aac4c4de671cfd540"],"layout":"IPY_MODEL_68d45123c6e440f584f41aecce7cf6be"}},"384c652f7f4f4055964ac4fca07b9c20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b7ce3d3be2744419e703094b6c42e2e","placeholder":"​","style":"IPY_MODEL_48deee40eacf4eb990e56316e87fc702","value":"[Epoch 1/35]: 100%"}},"1e9239ec7b0948228fdc3b8a775f3bf0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ea2e6fb75834bf7a9a36f209c6294b5","max":544,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e70d5eccb33e4684b97a001a080dd35c","value":544}},"74d25432ddc0409aac4c4de671cfd540":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eec74c1b7514b969e8d477b168cd43b","placeholder":"​","style":"IPY_MODEL_45f5e2c547c74708a07717aa18971af1","value":" 544/544 [01:45&lt;00:00,  6.43it/s]"}},"68d45123c6e440f584f41aecce7cf6be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b7ce3d3be2744419e703094b6c42e2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48deee40eacf4eb990e56316e87fc702":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ea2e6fb75834bf7a9a36f209c6294b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e70d5eccb33e4684b97a001a080dd35c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6eec74c1b7514b969e8d477b168cd43b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45f5e2c547c74708a07717aa18971af1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90300eba822f49d8b8e82197b8a316aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9f350b65f49485fb9d8142cf1ed6cfa","IPY_MODEL_fd14308d806b48cebc284c9285f0fa4c","IPY_MODEL_c7a120468be64a08850d47d384e8f314"],"layout":"IPY_MODEL_bf7058fd818a4d00affd003b45d14559"}},"e9f350b65f49485fb9d8142cf1ed6cfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3891032aa9244a9bbff9fcbc005ca367","placeholder":"​","style":"IPY_MODEL_9be9e4fcb12847f0b19fac944aba0ac7","value":"Dev Loss: 100%"}},"fd14308d806b48cebc284c9285f0fa4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f20a1fd78784e538548771b3b59be5d","max":148,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48e2a256774d472886d4a25ac253e0aa","value":148}},"c7a120468be64a08850d47d384e8f314":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b633cd1e6eb54de8b22093fae5d7a380","placeholder":"​","style":"IPY_MODEL_332438ac3025409eb53d5fadc7722d24","value":" 148/148 [00:15&lt;00:00, 11.86it/s]"}},"bf7058fd818a4d00affd003b45d14559":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3891032aa9244a9bbff9fcbc005ca367":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9be9e4fcb12847f0b19fac944aba0ac7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f20a1fd78784e538548771b3b59be5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48e2a256774d472886d4a25ac253e0aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b633cd1e6eb54de8b22093fae5d7a380":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"332438ac3025409eb53d5fadc7722d24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffc195c1284f40888fda6c42b4597555":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad3d1e4b3ef54387ba444aa95ce70a21","IPY_MODEL_49080faf1055459aaa5027c1cf9e03f3","IPY_MODEL_2cc52807121a4c2ebf3735fd04c66513"],"layout":"IPY_MODEL_d43509df337c471cbd16a2c2d6de3d8d"}},"ad3d1e4b3ef54387ba444aa95ce70a21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fe930b6df044cc8b281222fabaea59f","placeholder":"​","style":"IPY_MODEL_7309952c22af4e66b9c9e03a7e628133","value":"Test Loss: 100%"}},"49080faf1055459aaa5027c1cf9e03f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52b8fefcf3b0490980c9e51618f164da","max":166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff6006dcaa334fbebed53372c59d3229","value":166}},"2cc52807121a4c2ebf3735fd04c66513":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98bc9e320e4d4cbd877d8016dfd03818","placeholder":"​","style":"IPY_MODEL_6051a81198c74f56910fc1968d9d9837","value":" 166/166 [00:05&lt;00:00, 31.93it/s]"}},"d43509df337c471cbd16a2c2d6de3d8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fe930b6df044cc8b281222fabaea59f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7309952c22af4e66b9c9e03a7e628133":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52b8fefcf3b0490980c9e51618f164da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff6006dcaa334fbebed53372c59d3229":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98bc9e320e4d4cbd877d8016dfd03818":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6051a81198c74f56910fc1968d9d9837":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6b89528886648dba573734d554c5871":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5acbdcf9bb2403199125797db7c64f1","IPY_MODEL_d6c9a176ba8d48f788f42fffdc4a1e0d","IPY_MODEL_34bff980a41048e9a2751ea8d226a612"],"layout":"IPY_MODEL_c5a6691454524e01b14b996daeabb5b1"}},"d5acbdcf9bb2403199125797db7c64f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22e0a9a4ebeb42b386c7ff7e3ce8611a","placeholder":"​","style":"IPY_MODEL_fe8ed4e36692440bbfeb990768130dbf","value":"[Epoch 2/35]: 100%"}},"d6c9a176ba8d48f788f42fffdc4a1e0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0975b2acaa0a4147a1e219a36ba67871","max":544,"min":0,"orientation":"horizontal","style":"IPY_MODEL_057af433426047bd8d728734b5fe2e15","value":544}},"34bff980a41048e9a2751ea8d226a612":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e0755ff5e1d4e978a4dd8b29a3521ec","placeholder":"​","style":"IPY_MODEL_7456173f8fc64e7abe15e2ec51af9592","value":" 544/544 [00:03&lt;00:00, 161.64it/s]"}},"c5a6691454524e01b14b996daeabb5b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22e0a9a4ebeb42b386c7ff7e3ce8611a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe8ed4e36692440bbfeb990768130dbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0975b2acaa0a4147a1e219a36ba67871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"057af433426047bd8d728734b5fe2e15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e0755ff5e1d4e978a4dd8b29a3521ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7456173f8fc64e7abe15e2ec51af9592":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee299e976c7f4058800d6144a4ed658e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad45c3f4a17d4a0e86b42368e8f22f3d","IPY_MODEL_f2fe4b7b766d44e48808235da9156917","IPY_MODEL_9d0ddff4c267466380e6326dea9881a7"],"layout":"IPY_MODEL_1b16b46123ea4d91a0e2be9bced62e54"}},"ad45c3f4a17d4a0e86b42368e8f22f3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef59ad97fa0c499e825276bff0c99294","placeholder":"​","style":"IPY_MODEL_bdbd3e6e21d040418f82b5ef89a96db2","value":"Dev Loss: 100%"}},"f2fe4b7b766d44e48808235da9156917":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ac061cbd43d448b83bbb0ad1fc0a517","max":148,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bbeac6ada0a43f1b9629edf7df16686","value":148}},"9d0ddff4c267466380e6326dea9881a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1e7c08eb54d489fbaec4b79bab68a8c","placeholder":"​","style":"IPY_MODEL_2d58502ce27a4059956ca3b6cd7798fb","value":" 148/148 [00:14&lt;00:00, 12.08it/s]"}},"1b16b46123ea4d91a0e2be9bced62e54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef59ad97fa0c499e825276bff0c99294":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdbd3e6e21d040418f82b5ef89a96db2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ac061cbd43d448b83bbb0ad1fc0a517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bbeac6ada0a43f1b9629edf7df16686":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c1e7c08eb54d489fbaec4b79bab68a8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d58502ce27a4059956ca3b6cd7798fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97c7d8b523804de3a0106c0cbd62a808":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_030d7277a713416194ebe7d971c63117","IPY_MODEL_09cc159bfd3c45f4b8bcc559066beb46","IPY_MODEL_4289a42773e54827a33868ac81254fea"],"layout":"IPY_MODEL_98c05390cc51499bb952d574ec904e2a"}},"030d7277a713416194ebe7d971c63117":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8f92dceeb53495180c88a2d6fcf13c5","placeholder":"​","style":"IPY_MODEL_b581cc5ab9d94444b41604672a3b29b5","value":"Test Loss: 100%"}},"09cc159bfd3c45f4b8bcc559066beb46":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e925f009ba4f4bd09c31e95c5075124d","max":166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f8d1f82bef446af9e0ad6b2a17e2fc6","value":166}},"4289a42773e54827a33868ac81254fea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a91945574af64f458628124e865308fd","placeholder":"​","style":"IPY_MODEL_7ebb1e64ca644e49b6e6d747e7d15491","value":" 166/166 [00:00&lt;00:00, 435.53it/s]"}},"98c05390cc51499bb952d574ec904e2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8f92dceeb53495180c88a2d6fcf13c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b581cc5ab9d94444b41604672a3b29b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e925f009ba4f4bd09c31e95c5075124d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f8d1f82bef446af9e0ad6b2a17e2fc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a91945574af64f458628124e865308fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ebb1e64ca644e49b6e6d747e7d15491":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"992b8de9d0724bbab13bd18bfd1ef001":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4673aedc250428d8bf7153c32cc0933","IPY_MODEL_7bc0254167434b09b6fe92b448e02b99","IPY_MODEL_93d5a48921134d80898e4c76030495c7"],"layout":"IPY_MODEL_981117f4d7c643e287c7b78e71a316de"}},"f4673aedc250428d8bf7153c32cc0933":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6392aeef209e4b8f81a91cb06bc0aae3","placeholder":"​","style":"IPY_MODEL_4442247e409d45a3819e933c16124a45","value":"[Epoch 3/35]: 100%"}},"7bc0254167434b09b6fe92b448e02b99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08490dda3d06467bafccf7d70d8ae7d7","max":544,"min":0,"orientation":"horizontal","style":"IPY_MODEL_712091ea7ef64f959806b7a0a6224d6b","value":544}},"93d5a48921134d80898e4c76030495c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_527cf13e8bd14f6b9862ee9d57288d04","placeholder":"​","style":"IPY_MODEL_2f1c29403740460da037bc84af72b13d","value":" 544/544 [00:03&lt;00:00, 158.87it/s]"}},"981117f4d7c643e287c7b78e71a316de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6392aeef209e4b8f81a91cb06bc0aae3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4442247e409d45a3819e933c16124a45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08490dda3d06467bafccf7d70d8ae7d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"712091ea7ef64f959806b7a0a6224d6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"527cf13e8bd14f6b9862ee9d57288d04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f1c29403740460da037bc84af72b13d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6be5a5b591b4844945c6b2114587fb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7d32a5971b34c6b8fb539ca22d3d63e","IPY_MODEL_5bb53eb6cf1745ecb009a6c14163a925","IPY_MODEL_b9d4072cf93e429bb6db3f520b918d73"],"layout":"IPY_MODEL_6a1610f1f46f43e8bb879b9b6cc5c0ad"}},"c7d32a5971b34c6b8fb539ca22d3d63e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbddd5640bf44b629c8422484b8a19c9","placeholder":"​","style":"IPY_MODEL_bfde49eb05304e01ae59786280cee301","value":"Dev Loss: 100%"}},"5bb53eb6cf1745ecb009a6c14163a925":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d22fdc97d9b4d68a232f4bc857493e9","max":148,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00e14428b5ad4857ba05b8f55d28186c","value":148}},"b9d4072cf93e429bb6db3f520b918d73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e953ef48dc344d1b1c448cda564e6c1","placeholder":"​","style":"IPY_MODEL_fe01785b2af6416c94b33a4a60d167a5","value":" 148/148 [00:14&lt;00:00, 11.90it/s]"}},"6a1610f1f46f43e8bb879b9b6cc5c0ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbddd5640bf44b629c8422484b8a19c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfde49eb05304e01ae59786280cee301":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d22fdc97d9b4d68a232f4bc857493e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00e14428b5ad4857ba05b8f55d28186c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e953ef48dc344d1b1c448cda564e6c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe01785b2af6416c94b33a4a60d167a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdacf89318d64fcca79c5b70dc5fbd31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8952a884e48445179b8de69e909a2792","IPY_MODEL_6ba799230c744276a011bf9a296dd0e8","IPY_MODEL_6ce9d8ea6dc44ff0b272004228feece2"],"layout":"IPY_MODEL_7f6002a2a99e46598b8c47b739e5518d"}},"8952a884e48445179b8de69e909a2792":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4513a5fcde9460c93d0a653e7d9599c","placeholder":"​","style":"IPY_MODEL_d9354fd57c3242a8bb221098219fbeea","value":"Test Loss: 100%"}},"6ba799230c744276a011bf9a296dd0e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fd68f77ab15410096474fc49dd27389","max":166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45150cda34574b55a04937701109378a","value":166}},"6ce9d8ea6dc44ff0b272004228feece2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc15146099dd47a2a7662557e87a3a58","placeholder":"​","style":"IPY_MODEL_c663b61e9be54a048632d2ac4b0c5b21","value":" 166/166 [00:00&lt;00:00, 444.71it/s]"}},"7f6002a2a99e46598b8c47b739e5518d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4513a5fcde9460c93d0a653e7d9599c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9354fd57c3242a8bb221098219fbeea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fd68f77ab15410096474fc49dd27389":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45150cda34574b55a04937701109378a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc15146099dd47a2a7662557e87a3a58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c663b61e9be54a048632d2ac4b0c5b21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"043f921becf74ff59179894d7fe405a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c856369a9624541a7afbac9fd0c3ebf","IPY_MODEL_a994d964e7ca43ba8715cd54ee714acc","IPY_MODEL_ff17c8a21597451e9c332eed76dee005"],"layout":"IPY_MODEL_0b2d32168e1f44c19f11d13f62e5ac7b"}},"6c856369a9624541a7afbac9fd0c3ebf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5deae985c2a4286bf9e596afc0d1216","placeholder":"​","style":"IPY_MODEL_65799fbdcd2d4054944aa071eaced162","value":"100%"}},"a994d964e7ca43ba8715cd54ee714acc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2f4a856f309408d95d2a5751b85a13d","max":166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed8f88eab8584064af348e6965766337","value":166}},"ff17c8a21597451e9c332eed76dee005":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebb440017e9a4e93aa4d6b4635c37162","placeholder":"​","style":"IPY_MODEL_2058c96efee64868a5e9d4ab8039207a","value":" 166/166 [00:00&lt;00:00, 425.79it/s]"}},"0b2d32168e1f44c19f11d13f62e5ac7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5deae985c2a4286bf9e596afc0d1216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65799fbdcd2d4054944aa071eaced162":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2f4a856f309408d95d2a5751b85a13d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed8f88eab8584064af348e6965766337":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebb440017e9a4e93aa4d6b4635c37162":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2058c96efee64868a5e9d4ab8039207a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}